#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬

éªŒè¯ï¼š
1. å¹¶å‘è·å–åŠŸèƒ½æ­£å¸¸
2. å¿«é€Ÿå¤±è´¥ç­–ç•¥åº”ç”¨
3. é…ç½®å‚æ•°æ­£ç¡®
"""

import sys
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥æ¨¡å—
from config import CONCURRENT_CONFIG, FAST_FAIL_CONFIG, REQUEST_CONFIG
from concurrent_data_fetcher import ConcurrentDataFetcher
from industry_classification_complete_getter import IndustryClassificationCompleteGetter


def test_config_optimization():
    """æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®ä¼˜åŒ–"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1ï¼šé…ç½®ä¼˜åŒ–éªŒè¯")
    logger.info("=" * 60)
    
    # æ£€æŸ¥å¹¶å‘é…ç½®
    logger.info(f"å¹¶å‘é…ç½®å¯ç”¨: {CONCURRENT_CONFIG.get('enabled')}")
    logger.info(f"æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°: {CONCURRENT_CONFIG.get('max_workers')}")
    logger.info(f"å¿«é€Ÿå¤±è´¥ç­–ç•¥: {CONCURRENT_CONFIG.get('use_fast_fail')}")
    
    # æ£€æŸ¥å¿«é€Ÿå¤±è´¥é…ç½®
    logger.info(f"è¯·æ±‚è¶…æ—¶: {FAST_FAIL_CONFIG.get('request_timeout')}ç§’")
    logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {FAST_FAIL_CONFIG.get('max_retries')}")
    logger.info(f"é‡è¯•å»¶è¿Ÿ: {FAST_FAIL_CONFIG.get('retry_delays')}")
    logger.info(f"æœ€å°æˆåŠŸç‡é˜ˆå€¼: {FAST_FAIL_CONFIG.get('min_success_rate')*100:.1f}%")
    
    # æ£€æŸ¥è¯·æ±‚é…ç½®
    logger.info(f"è¯·æ±‚å»¶è¿ŸèŒƒå›´: {REQUEST_CONFIG['delay_between_requests']}")
    logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {REQUEST_CONFIG['max_retries']}")
    
    # éªŒè¯ä¼˜åŒ–å‚æ•°
    assert CONCURRENT_CONFIG.get('max_workers', 5) >= 1, "å¹¶å‘çº¿ç¨‹æ•°å¿…é¡» >= 1"
    assert FAST_FAIL_CONFIG.get('request_timeout', 10) <= 20, "è¯·æ±‚è¶…æ—¶åº”è¯¥ <= 20ç§’"
    assert REQUEST_CONFIG['max_retries'] <= 5, "é‡è¯•æ¬¡æ•°åº”è¯¥ <= 5"
    
    logger.info("âœ… é…ç½®ä¼˜åŒ–éªŒè¯é€šè¿‡\n")


def mock_fetch_function(stock_code: str, stock_name: str) -> dict:
    """æ¨¡æ‹Ÿçš„è‚¡ç¥¨æ•°æ®è·å–å‡½æ•°"""
    time.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚æ—¶é—´
    return {
        'real_estate_2023': 1000000,
        'real_estate_2024': 1500000,
        'shenwan_level1': 'æˆ¿åœ°äº§',
        'shenwan_level2': 'æˆ¿åœ°äº§å¼€å‘',
        'shenwan_level3': 'æˆ¿åœ°äº§å¼€å‘',
        'source': 'mock'
    }


def test_concurrent_fetcher():
    """æµ‹è¯•å¹¶å‘è·å–å™¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•2ï¼šå¹¶å‘è·å–å™¨åŠŸèƒ½")
    logger.info("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_stocks = [
        {'code': '000001', 'name': 'å¹³å®‰é“¶è¡Œ'},
        {'code': '000002', 'name': 'ä¸‡ç§‘A'},
        {'code': '000858', 'name': 'äº”ç²®æ¶²'},
        {'code': '600036', 'name': 'æ‹›å•†é“¶è¡Œ'},
        {'code': '600519', 'name': 'è´µå·èŒ…å°'},
    ]
    
    # åˆ›å»ºå¹¶å‘è·å–å™¨
    fetcher = ConcurrentDataFetcher(
        fetch_func=mock_fetch_function,
        max_workers=2,  # æµ‹è¯•ç”¨2ä¸ªçº¿ç¨‹
        logger_obj=logger
    )
    
    # æµ‹è¯•å¹¶å‘è·å–
    start_time = time.time()
    results, stats = fetcher.fetch_concurrent(test_stocks, show_progress=False)
    elapsed = time.time() - start_time
    
    # éªŒè¯ç»“æœ
    assert len(results) == len(test_stocks), f"ç»“æœæ•°é‡ä¸ç¬¦: {len(results)} vs {len(test_stocks)}"
    assert stats['success'] == len(test_stocks), "æ‰€æœ‰è‚¡ç¥¨åº”è¯¥è·å–æˆåŠŸ"
    assert stats['success_rate'] == 1.0, "æˆåŠŸç‡åº”è¯¥æ˜¯100%"
    
    logger.info(f"âœ… å¹¶å‘è·å–æˆåŠŸ: {len(results)}/{len(test_stocks)} åªè‚¡ç¥¨")
    logger.info(f"â±ï¸ è€—æ—¶: {elapsed:.2f}ç§’ï¼ˆå¹³å‡ {stats['avg_time']:.2f}ç§’/ä¸ªï¼‰")
    
    # è®¡ç®—æ€§èƒ½æå‡
    # ä¸²è¡Œå¤„ç†æ—¶é—´ä¼°è®¡ï¼ˆæ¯ä¸ª 0.1ç§’ + 0.1ç§’å»¶è¿Ÿï¼‰
    serial_time = len(test_stocks) * 0.2
    speedup = serial_time / elapsed
    logger.info(f"ğŸš€ æ€§èƒ½æå‡: {speedup:.1f}å€ï¼ˆä»{serial_time:.1f}ç§’ â†’ {elapsed:.1f}ç§’ï¼‰\n")


def test_industry_classification_getter():
    """æµ‹è¯•è¡Œä¸šåˆ†ç±»è·å–å™¨çš„æºè¿‡æ»¤"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•3ï¼šè¡Œä¸šåˆ†ç±»è·å–å™¨æºè¿‡æ»¤")
    logger.info("=" * 60)
    
    # åˆ›å»ºè¡Œä¸šåˆ†ç±»è·å–å™¨
    getter = IndustryClassificationCompleteGetter(logger=logger)
    
    # éªŒè¯æºè¿‡æ»¤åŠŸèƒ½
    test_sources = [
        ('eastmoney_quote', {'name': 'ä¸œæ–¹è´¢å¯Œè¡Œæƒ…', 'priority': 1}),
        ('sina_shenwan', {'name': 'æ–°æµªè´¢ç»', 'priority': 3}),
        ('tencent_quote', {'name': 'è…¾è®¯è´¢ç»', 'priority': 5}),
        ('netease_f10', {'name': 'ç½‘æ˜“è´¢ç»', 'priority': 6}),
    ]
    
    # æ‰§è¡Œæºè¿‡æ»¤
    active_sources = getter._filter_sources_by_success_rate(
        test_sources,
        min_success_rate=0.05,
        show_progress=True
    )
    
    # éªŒè¯è¿‡æ»¤ç»“æœ
    source_names = [s[1]['name'] for s in active_sources]
    
    # è…¾è®¯è´¢ç»å’Œç½‘æ˜“è´¢ç»åº”è¯¥è¢«è¿‡æ»¤æ‰ï¼ˆæˆåŠŸç‡0%ï¼‰
    assert 'è…¾è®¯è´¢ç»' not in source_names, "è…¾è®¯è´¢ç»åº”è¯¥è¢«è¿‡æ»¤"
    assert 'ç½‘æ˜“è´¢ç»' not in source_names, "ç½‘æ˜“è´¢ç»åº”è¯¥è¢«è¿‡æ»¤"
    assert 'ä¸œæ–¹è´¢å¯Œè¡Œæƒ…' in source_names, "ä¸œæ–¹è´¢å¯Œåº”è¯¥è¢«ä¿ç•™"
    assert 'æ–°æµªè´¢ç»' in source_names, "æ–°æµªè´¢ç»åº”è¯¥è¢«ä¿ç•™"
    
    logger.info(f"âœ… æºè¿‡æ»¤æˆåŠŸ: ä¿ç•™{len(active_sources)}/{len(test_sources)}ä¸ªæº\n")


def test_performance_estimate():
    """æ€§èƒ½æå‡ä¼°è®¡"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•4ï¼šæ€§èƒ½æå‡ä¼°è®¡")
    logger.info("=" * 60)
    
    # å‚æ•°
    total_stocks = 5171
    max_workers = CONCURRENT_CONFIG.get('max_workers', 5)
    avg_delay = 0.35  # (0.2 + 0.5) / 2
    
    # ä¸²è¡Œå¤„ç†æ—¶é—´
    serial_time = total_stocks * (avg_delay + 0.1)  # åŠ ä¸Šç½‘ç»œè¯·æ±‚æ—¶é—´
    
    # å¹¶å‘å¤„ç†æ—¶é—´ï¼ˆç†æƒ³æƒ…å†µï¼‰
    concurrent_time = (total_stocks / max_workers) * (avg_delay + 0.1)
    
    # å®é™…å¹¶å‘æ—¶é—´ï¼ˆè€ƒè™‘å¼€é”€ï¼‰
    actual_concurrent_time = concurrent_time * 1.1
    
    # æ€§èƒ½æå‡
    speedup = serial_time / actual_concurrent_time
    
    logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_stocks}")
    logger.info(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
    logger.info(f"å¹³å‡å»¶è¿Ÿ: {avg_delay}ç§’")
    logger.info("")
    logger.info(f"ä¸²è¡Œå¤„ç†æ—¶é—´: {serial_time/60:.1f}åˆ†é’Ÿ ({serial_time:.0f}ç§’)")
    logger.info(f"å¹¶å‘å¤„ç†æ—¶é—´: {actual_concurrent_time/60:.1f}åˆ†é’Ÿ ({actual_concurrent_time:.0f}ç§’)")
    logger.info(f"æ€§èƒ½æå‡: {speedup:.1f}å€")
    logger.info("")
    logger.info(f"âœ… é¢„æœŸæå‡: ä»{serial_time/3600:.1f}å°æ—¶ â†’ {actual_concurrent_time/3600:.1f}å°æ—¶\n")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("\n")
    logger.info("ğŸ§ª æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¥—ä»¶")
    logger.info("=" * 60)
    
    try:
        # è¿è¡Œæµ‹è¯•
        test_config_optimization()
        test_concurrent_fetcher()
        test_industry_classification_getter()
        test_performance_estimate()
        
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("=" * 60)
        
        return 0
        
    except AssertionError as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return 1
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
