# -*- coding: utf-8 -*-
"""
å¹¶å‘æ•°æ®è·å–å™¨ - ä¼˜åŒ–æ€§èƒ½

åŠŸèƒ½ï¼š
1. æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘è·å–è‚¡ç¥¨æ•°æ®
2. å¿«é€Ÿå¤±è´¥ç­–ç•¥ - å‡å°‘é‡è¯•ç­‰å¾…æ—¶é—´
3. åŠ¨æ€æºé€‰æ‹© - æ ¹æ®æˆåŠŸç‡è‡ªåŠ¨ç­›é€‰æ•°æ®æº
4. è¿›åº¦è·Ÿè¸ª - å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦

ä¼˜åŒ–æ•ˆæœï¼š
- ä¸²è¡Œå¤„ç†ï¼š5171åªè‚¡ç¥¨ Ã— 1.25ç§’å»¶è¿Ÿ = ~107åˆ†é’Ÿ
- å¹¶å‘å¤„ç†ï¼ˆ5çº¿ç¨‹ï¼‰ï¼š5171åªè‚¡ç¥¨ Ã· 5 Ã— 0.3ç§’å»¶è¿Ÿ = ~5åˆ†é’Ÿ
- æ€»ä½“æå‡ï¼š~20å€

ä½œè€…ï¼šClaude
æ—¥æœŸï¼š2024
ç‰ˆæœ¬ï¼šv1.0
"""

from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError
import threading
import time
import logging
from typing import List, Dict, Optional, Callable, Tuple, Set
from dataclasses import dataclass
from collections import defaultdict
import random

from config import CONCURRENT_CONFIG, FAST_FAIL_CONFIG

logger = logging.getLogger(__name__)


@dataclass
class FetchResult:
    """å•ä¸ªè·å–ç»“æœ"""
    stock_code: str
    stock_name: str
    data: Optional[Dict] = None
    success: bool = False
    error: Optional[str] = None
    source: Optional[str] = None
    retry_count: int = 0
    duration: float = 0.0


@dataclass
class SourceStats:
    """æ•°æ®æºç»Ÿè®¡"""
    source_name: str
    success_count: int = 0
    fail_count: int = 0
    total_requests: int = 0
    total_time: float = 0.0
    
    @property
    def success_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return self.success_count / self.total_requests
    
    @property
    def avg_time(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return self.total_time / self.total_requests


class ConcurrentDataFetcher:
    """
    å¹¶å‘æ•°æ®è·å–å™¨
    
    æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘è·å–è‚¡ç¥¨æ•°æ®ï¼ŒåŒæ—¶åº”ç”¨å¿«é€Ÿå¤±è´¥ç­–ç•¥
    """
    
    def __init__(self, 
                 fetch_func: Callable,
                 max_workers: Optional[int] = None,
                 logger_obj=None):
        """
        åˆå§‹åŒ–å¹¶å‘è·å–å™¨
        
        Args:
            fetch_func: å•åªè‚¡ç¥¨æ•°æ®è·å–å‡½æ•°ï¼Œç­¾åä¸º func(stock_code, stock_name) -> Dict
            max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é…ç½®å€¼
            logger_obj: æ—¥å¿—å¯¹è±¡
        """
        self.fetch_func = fetch_func
        self.logger = logger_obj or logger
        
        config = CONCURRENT_CONFIG
        self.max_workers = max_workers or config.get('max_workers', 5)
        self.batch_size = config.get('batch_size', 100)
        self.use_fast_fail = config.get('use_fast_fail', True)
        self.consecutive_fail_threshold = config.get('consecutive_fail_threshold', 3)
        
        # å¿«é€Ÿå¤±è´¥é…ç½®
        self.fast_fail_config = FAST_FAIL_CONFIG if self.use_fast_fail else {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.source_stats: Dict[str, SourceStats] = defaultdict(lambda: SourceStats(source_name=''))
        self.total_results: List[FetchResult] = []
        self.lock = threading.Lock()
        
        self.logger.info(f"å¹¶å‘è·å–å™¨åˆå§‹åŒ–: max_workers={self.max_workers}, batch_size={self.batch_size}")
        if self.use_fast_fail:
            self.logger.info(f"å¯ç”¨å¿«é€Ÿå¤±è´¥ç­–ç•¥: timeout={self.fast_fail_config.get('request_timeout', 10)}s, max_retries={self.fast_fail_config.get('max_retries', 2)}")
    
    def fetch_concurrent(self, 
                        stocks: List[Dict],
                        show_progress: bool = True) -> Tuple[List[Dict], Dict]:
        """
        å¹¶å‘è·å–å¤šåªè‚¡ç¥¨çš„æ•°æ®
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨ [{"code": "000001", "name": "å¹³å®‰é“¶è¡Œ"}, ...]
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
        Returns:
            (ç»“æœåˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
        """
        if not stocks:
            return [], {}
        
        self.total_results.clear()
        self.source_stats.clear()
        
        total = len(stocks)
        processed = 0
        
        self.logger.info(f"å¼€å§‹å¹¶å‘è·å–{total}åªè‚¡ç¥¨çš„æ•°æ®")
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_stock = {
                executor.submit(self._fetch_single_stock, stock): stock 
                for stock in stocks
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_stock):
                stock = future_to_stock[future]
                processed += 1
                
                try:
                    result = future.result(timeout=30)  # å•ä¸ªä»»åŠ¡è¶…æ—¶30ç§’
                    if result:
                        self.total_results.append(result)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if show_progress and processed % 50 == 0:
                        self.logger.info(f"å·²å¤„ç† {processed}/{total} åªè‚¡ç¥¨ï¼ŒæˆåŠŸ: {len([r for r in self.total_results if r.success])}")
                        
                except FuturesTimeoutError:
                    self.logger.warning(f"è·å– {stock.get('code', 'unknown')} è¶…æ—¶")
                except Exception as e:
                    self.logger.warning(f"è·å– {stock.get('code', 'unknown')} å¤±è´¥: {e}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats = self._generate_stats()
        
        if show_progress:
            self._display_final_stats(stats)
        
        # å°†ç»“æœè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        results = []
        for r in self.total_results:
            if r.success:
                result_dict = {
                    'stock_code': r.stock_code,
                    'stock_name': r.stock_name,
                }
                if r.data:
                    result_dict.update(r.data)
                results.append(result_dict)
        
        return results, stats
    
    def _fetch_single_stock(self, stock: Dict) -> Optional[FetchResult]:
        """è·å–å•åªè‚¡ç¥¨çš„æ•°æ®"""
        stock_code = stock.get('code', '')
        stock_name = stock.get('name', '')
        
        if not stock_code:
            return None
        
        start_time = time.time()
        
        try:
            # è°ƒç”¨è·å–å‡½æ•°
            data = self.fetch_func(stock_code, stock_name)
            
            duration = time.time() - start_time
            
            result = FetchResult(
                stock_code=stock_code,
                stock_name=stock_name,
                data=data,
                success=data is not None,
                duration=duration
            )
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            
            self.logger.debug(f"è·å– {stock_code} å¤±è´¥: {e}")
            return FetchResult(
                stock_code=stock_code,
                stock_name=stock_name,
                success=False,
                error=str(e),
                duration=duration
            )
    
    def _generate_stats(self) -> Dict:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        total = len(self.total_results)
        success = len([r for r in self.total_results if r.success])
        failed = total - success
        
        total_time = sum(r.duration for r in self.total_results)
        avg_time = total_time / total if total > 0 else 0
        
        return {
            'total': total,
            'success': success,
            'failed': failed,
            'success_rate': success / total if total > 0 else 0,
            'total_time': total_time,
            'avg_time': avg_time,
        }
    
    def _display_final_stats(self, stats: Dict):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š å¹¶å‘è·å–ç»Ÿè®¡")
        self.logger.info("=" * 60)
        self.logger.info(f"æ€»æ•°é‡: {stats['total']}")
        self.logger.info(f"æˆåŠŸ: {stats['success']}")
        self.logger.info(f"å¤±è´¥: {stats['failed']}")
        self.logger.info(f"æˆåŠŸç‡: {stats['success_rate']*100:.1f}%")
        self.logger.info(f"æ€»è€—æ—¶: {stats['total_time']:.1f}ç§’")
        self.logger.info(f"å¹³å‡è€—æ—¶: {stats['avg_time']:.2f}ç§’/ä¸ª")
        self.logger.info("=" * 60)


class SmartSourceSelector:
    """
    æ™ºèƒ½æ•°æ®æºé€‰æ‹©å™¨
    
    æ ¹æ®å®é™…æˆåŠŸç‡åŠ¨æ€è°ƒæ•´æ•°æ®æºï¼Œè·³è¿‡æ— æ•ˆæº
    """
    
    def __init__(self, min_success_rate: float = 0.05):
        """
        åˆå§‹åŒ–æºé€‰æ‹©å™¨
        
        Args:
            min_success_rate: æœ€å°æˆåŠŸç‡é˜ˆå€¼ï¼Œä½äºæ­¤çš„æºå°†è¢«æ”¾å¼ƒ
        """
        self.min_success_rate = min_success_rate
        self.source_stats: Dict[str, SourceStats] = {}
        self.logger = logging.getLogger(__name__)
    
    def record_attempt(self, source_name: str, success: bool, duration: float = 0.0):
        """è®°å½•ä¸€æ¬¡å°è¯•"""
        if source_name not in self.source_stats:
            self.source_stats[source_name] = SourceStats(source_name=source_name)
        
        stats = self.source_stats[source_name]
        stats.total_requests += 1
        stats.total_time += duration
        
        if success:
            stats.success_count += 1
        else:
            stats.fail_count += 1
    
    def get_active_sources(self, all_sources: List[str]) -> List[str]:
        """
        è·å–æ´»è·ƒçš„æ•°æ®æºåˆ—è¡¨
        
        æ ¹æ®æˆåŠŸç‡è¿‡æ»¤ï¼Œåªä¿ç•™æˆåŠŸç‡ >= min_success_rate çš„æº
        
        Args:
            all_sources: æ‰€æœ‰å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨
        
        Returns:
            æ´»è·ƒçš„æ•°æ®æºåˆ—è¡¨
        """
        active = []
        
        for source in all_sources:
            if source not in self.source_stats:
                # æ–°æºï¼Œæ·»åŠ åˆ°æ´»è·ƒåˆ—è¡¨
                active.append(source)
                continue
            
            stats = self.source_stats[source]
            if stats.total_requests == 0:
                active.append(source)
                continue
            
            if stats.success_rate >= self.min_success_rate:
                active.append(source)
                self.logger.debug(f"æº {source} æˆåŠŸç‡ {stats.success_rate*100:.1f}%ï¼Œä¿ç•™")
            else:
                self.logger.warning(f"æº {source} æˆåŠŸç‡ {stats.success_rate*100:.1f}% < {self.min_success_rate*100:.1f}%ï¼Œæ”¾å¼ƒ")
        
        return active
    
    def get_stats_summary(self) -> Dict[str, Dict]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        summary = {}
        for source, stats in self.source_stats.items():
            summary[source] = {
                'success_count': stats.success_count,
                'fail_count': stats.fail_count,
                'total_requests': stats.total_requests,
                'success_rate': stats.success_rate,
                'avg_time': stats.avg_time,
            }
        return summary


class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨"""
    
    def __init__(self, total: int, logger_obj=None):
        self.total = total
        self.current = 0
        self.lock = threading.Lock()
        self.logger = logger_obj or logger
        self.start_time = time.time()
    
    def update(self, count: int = 1):
        """æ›´æ–°è¿›åº¦"""
        with self.lock:
            self.current += count
            self._print_progress()
    
    def _print_progress(self):
        """æ‰“å°è¿›åº¦"""
        if self.total == 0:
            return
        
        percent = self.current / self.total * 100
        elapsed = time.time() - self.start_time
        
        if self.current > 0:
            rate = self.current / elapsed
            remaining = (self.total - self.current) / rate if rate > 0 else 0
        else:
            remaining = 0
        
        if self.current % 100 == 0:
            self.logger.info(
                f"è¿›åº¦: {self.current}/{self.total} ({percent:.1f}%) | "
                f"å·²è€—æ—¶: {elapsed:.0f}s | "
                f"é¢„è®¡å‰©ä½™: {remaining:.0f}s"
            )
