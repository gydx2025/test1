#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§æ•°æ®è·å–è„šæœ¬

åŠŸèƒ½ï¼š
1. è·å–å…¨éƒ¨Aè‚¡ä¸Šå¸‚å…¬å¸2023å¹´æœ«å’Œ2024å¹´æœ«çš„éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§æ•°æ®
2. åŒ…å«å…¬å¸åç§°ã€è‚¡ç¥¨ä»£ç ã€èµ„äº§é‡‘é¢ã€è¡Œä¸šåˆ†ç±»ä¿¡æ¯
3. è¾“å‡ºä¸ºExcelæ–‡ä»¶ï¼ŒåŒ…å«æ•°æ®æ¸…æ´—å’ŒéªŒè¯

æ•°æ®æºä¼˜å…ˆçº§ï¼š
1. å·¨æ½®èµ„è®¯ (cninfo.com.cn) - å®˜æ–¹æ•°æ®æºï¼Œåçˆ¬è™«ç›¸å¯¹æ¸©å’Œ
2. ä¸œæ–¹è´¢å¯Œç½‘ (eastmoney.com) - éœ€è¦ä¸¥æ ¼çš„åçˆ¬è™«å¤„ç†
3. æ–°æµªè´¢ç» (sina.com) - å¤‡é€‰æ–¹æ¡ˆ

åçˆ¬è™«æªæ–½ï¼š
1. User-Agentè½®æ¢
2. éšæœºè¯·æ±‚å»¶è¿Ÿ
3. æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
4. å®Œæ•´HTTPè¯·æ±‚å¤´
5. Sessionè¿æ¥æ± ç®¡ç†
6. è¯·æ±‚çŠ¶æ€ç›‘æ§å’Œæ—¥å¿—è®°å½•

ä½œè€…ï¼šClaude
æ—¥æœŸï¼š2024
ç‰ˆæœ¬ï¼š2.3.0 - ç´§æ€¥ä¿®å¤ï¼šå¤šæ•°æ®æºè¡¥å…¨æœºåˆ¶ + AkShare + ç½‘é¡µçˆ¬è™« + ä¸¥æ ¼éªŒè¯
"""

import pandas as pd
import requests
import time
import logging
import os
import re
import random
import pickle
import json
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Tuple
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥é…ç½®
from config import (
    DATA_SOURCES, REQUEST_CONFIG, USER_AGENT_POOL,
    HEADERS_CONFIG, PROXY_CONFIG, OUTPUT_CONFIG,
    DATA_CLEANING_CONFIG, LOGGING_CONFIG, INDUSTRY_SOURCES,
    INDUSTRY_CACHE_CONFIG, LOCAL_CACHE_CONFIG,
)

from industry_classification_fetcher import IndustryClassificationFetcher
from industry_classification_complete_getter import IndustryClassificationCompleteGetter

from local_cache import IndustryCacheStore, StockCacheStore
from local_cache.cache_store import build_local_cache_config

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AStockRealEstateDataCollector:
    """Aè‚¡éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§æ•°æ®æ”¶é›†å™¨ - å¸¦åçˆ¬è™«å¤„ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨ï¼Œé…ç½®åçˆ¬è™«æªæ–½"""
        self.session = requests.Session()
        
        # åˆå§‹åŒ–è¯·æ±‚å¤´ï¼ˆä¼šåœ¨æ¯æ¬¡è¯·æ±‚æ—¶åŠ¨æ€æ›´æ–°User-Agentï¼‰
        self._update_headers()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.request_count = 0
        self.failed_request_count = 0
        self.retry_count = 0
        
        # ä»£ç†æ± 
        self.proxy_index = 0
        self.proxies = PROXY_CONFIG.get('proxies', []) if PROXY_CONFIG.get('enabled') else []
        
        # æ•°æ®å­˜å‚¨
        self.company_data = []
        self.data_2023 = []
        self.data_2024 = []

        # æœ¬åœ°ç¼“å­˜å±‚ï¼ˆSQLite + pickleï¼‰ï¼Œç”¨äºå¿«é€Ÿå¯åŠ¨/å‰ç¼€æŸ¥è¯¢
        self.local_cache_enabled = bool(LOCAL_CACHE_CONFIG.get('enabled', True))
        self.stock_cache_store = None
        self.industry_cache_store = None
        if self.local_cache_enabled:
            try:
                cache_cfg = build_local_cache_config(LOCAL_CACHE_CONFIG)
                self.stock_cache_store = StockCacheStore(cache_cfg)
                self.industry_cache_store = IndustryCacheStore(cache_cfg)
            except Exception as e:
                logger.warning(f"åˆå§‹åŒ–æœ¬åœ°ç¼“å­˜å±‚å¤±è´¥ï¼Œå°†é€€åŒ–ä¸ºæ—§ç¼“å­˜æœºåˆ¶: {e}")
                self.local_cache_enabled = False

        # ç”¨äºç¡®ä¿å•æ¬¡è¿è¡Œå†…ä»…åˆ›å»ºä¸€æ¬¡ç¼“å­˜å¤‡ä»½
        self._local_cache_backup_timestamp: Optional[str] = None
        self._local_cache_backup_done: bool = False
        self._local_cache_dirty: bool = False

        # è¡Œä¸šåˆ†ç±»ç¼“å­˜ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜å±‚ï¼Œå…¶æ¬¡ä½¿ç”¨æ—§çš„pklç¼“å­˜ï¼‰
        self.industry_cache: Dict[str, Dict] = {}
        self._load_industry_cache()

        self.industry_fetcher = IndustryClassificationFetcher(
            make_request=self._make_request,
            cache=self.industry_cache,
            sources_config=INDUSTRY_SOURCES,
            logger=logger,
        )
        self.industry_fetcher.purge_invalid_cache_entries()
        
        logger.info("æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ - åçˆ¬è™«æªæ–½å·²å¯ç”¨")
        logger.info(f"User-Agentæ± å¤§å°: {len(USER_AGENT_POOL)}")
        logger.info(f"è¯·æ±‚å»¶è¿ŸèŒƒå›´: {REQUEST_CONFIG['delay_between_requests']}")
        logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {REQUEST_CONFIG['max_retries']}")
        logger.info(f"æœ¬åœ°ç¼“å­˜å±‚å·²å¯ç”¨: {self.local_cache_enabled}")
        logger.info(f"è¡Œä¸šåˆ†ç±»æ—§ç¼“å­˜å·²å¯ç”¨: {INDUSTRY_CACHE_CONFIG.get('enabled')}")
    
    def _update_headers(self, referer: str = None):
        """æ›´æ–°è¯·æ±‚å¤´ï¼Œè½®æ¢User-Agent"""
        # éšæœºé€‰æ‹©User-Agent
        user_agent = random.choice(USER_AGENT_POOL)
        
        # æ„å»ºå®Œæ•´è¯·æ±‚å¤´
        headers = HEADERS_CONFIG.copy()
        headers['User-Agent'] = user_agent
        
        # æ·»åŠ Refererï¼ˆå¦‚æœæä¾›ï¼‰
        if referer:
            headers['Referer'] = referer
        
        self.session.headers.update(headers)
        logger.debug(f"å·²æ›´æ–°User-Agent: {user_agent[:50]}...")
    
    def _get_random_delay(self) -> float:
        """è·å–éšæœºå»¶è¿Ÿæ—¶é—´"""
        delay_range = REQUEST_CONFIG['delay_between_requests']
        if isinstance(delay_range, tuple):
            return random.uniform(delay_range[0], delay_range[1])
        return delay_range
    
    def _get_backoff_delay(self, retry_attempt: int) -> float:
        """è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿæ—¶é—´"""
        if REQUEST_CONFIG.get('use_exponential_backoff', True):
            base_delay = REQUEST_CONFIG['retry_delay']
            factor = REQUEST_CONFIG.get('backoff_factor', 2)
            return base_delay * (factor ** retry_attempt)
        return REQUEST_CONFIG['retry_delay']
    
    def _rotate_proxy(self):
        """è½®æ¢ä»£ç†"""
        if not self.proxies:
            return None
        
        self.proxy_index = (self.proxy_index + 1) % len(self.proxies)
        proxy = self.proxies[self.proxy_index]
        logger.info(f"åˆ‡æ¢ä»£ç†: {proxy.get('http', 'N/A')}")
        return proxy
    
    def _make_request(self, url: str, params: dict = None, method: str = 'GET', 
                      referer: str = None) -> Optional[requests.Response]:
        """
        å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦åçˆ¬è™«å¤„ç†ï¼‰
        
        Args:
            url: è¯·æ±‚URL
            params: è¯·æ±‚å‚æ•°
            method: è¯·æ±‚æ–¹æ³•
            referer: Refererå¤´
            
        Returns:
            å“åº”å¯¹è±¡æˆ–None
        """
        max_retries = REQUEST_CONFIG['max_retries']
        
        for retry_attempt in range(max_retries):
            try:
                # æ›´æ–°è¯·æ±‚å¤´ï¼ˆè½®æ¢User-Agentï¼‰
                self._update_headers(referer)
                
                # è·å–ä»£ç†
                proxy = None
                if PROXY_CONFIG.get('enabled') and self.proxies:
                    proxy = self.proxies[self.proxy_index]
                
                # æ·»åŠ éšæœºå»¶è¿Ÿï¼ˆç¬¬ä¸€æ¬¡è¯·æ±‚é™¤å¤–ï¼‰
                if self.request_count > 0:
                    delay = self._get_random_delay()
                    logger.debug(f"ç­‰å¾… {delay:.2f}ç§’...")
                    time.sleep(delay)
                
                # å‘é€è¯·æ±‚
                logger.debug(f"å‘é€è¯·æ±‚: {url} (å°è¯• {retry_attempt + 1}/{max_retries})")
                
                if method.upper() == 'GET':
                    response = self.session.get(
                        url, 
                        params=params, 
                        timeout=REQUEST_CONFIG['timeout'],
                        proxies=proxy
                    )
                else:
                    response = self.session.post(
                        url, 
                        data=params, 
                        timeout=REQUEST_CONFIG['timeout'],
                        proxies=proxy
                    )
                
                response.raise_for_status()
                self.request_count += 1
                
                logger.debug(f"è¯·æ±‚æˆåŠŸ: {response.status_code}")
                return response
                
            except requests.exceptions.Timeout:
                self.failed_request_count += 1
                self.retry_count += 1
                logger.warning(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {retry_attempt + 1}/{max_retries})")
                
            except requests.exceptions.HTTPError as e:
                self.failed_request_count += 1
                status_code = e.response.status_code if e.response else None
                
                # 429è¡¨ç¤ºè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œéœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                if status_code == 429:
                    logger.warning(f"è¯·æ±‚é¢‘ç‡è¿‡é«˜(429)ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´...")
                    backoff_delay = self._get_backoff_delay(retry_attempt) * 2
                    time.sleep(backoff_delay)
                    self.retry_count += 1
                    continue
                
                # 403å¯èƒ½æ˜¯è¢«å°ç¦ï¼Œå°è¯•è½®æ¢ä»£ç†æˆ–User-Agent
                elif status_code == 403:
                    logger.warning(f"è¯·æ±‚è¢«æ‹’ç»(403)ï¼Œå°è¯•è½®æ¢ç­–ç•¥...")
                    if PROXY_CONFIG.get('rotate_on_failure') and self.proxies:
                        self._rotate_proxy()
                    self.retry_count += 1
                    continue
                
                else:
                    logger.warning(f"HTTPé”™è¯¯: {status_code} - {e}")
                    break
                
            except requests.exceptions.ConnectionError:
                self.failed_request_count += 1
                self.retry_count += 1
                logger.warning(f"è¿æ¥é”™è¯¯ (å°è¯• {retry_attempt + 1}/{max_retries})")
                
            except Exception as e:
                self.failed_request_count += 1
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
                break
            
            # å¦‚æœéœ€è¦é‡è¯•ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
            if retry_attempt < max_retries - 1:
                backoff_delay = self._get_backoff_delay(retry_attempt)
                logger.info(f"ç­‰å¾… {backoff_delay:.1f}ç§’åé‡è¯•...")
                time.sleep(backoff_delay)
        
        logger.error(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {url}")
        return None
        
    def validate_stock_code(self, code: str) -> bool:
        """
        ä¸¥æ ¼éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
        
        åªæ¥å—çœŸå®Aè‚¡ä»£ç ï¼š
        - 6å¼€å¤´ï¼šæ²ªå¸‚ä¸»æ¿
        - 0å¼€å¤´ï¼šæ·±å¸‚ä¸»æ¿/ä¸­å°æ¿
        - 3å¼€å¤´ï¼šåˆ›ä¸šæ¿
        - 8å¼€å¤´ï¼šåŒ—äº¤æ‰€
        - 4å¼€å¤´ï¼šåŒ—äº¤æ‰€
        
        æ‹’ç»ï¼š
        - 920000ç­‰é”™è¯¯ä»£ç 
        - é6ä½æ•°å­—
        """
        if not isinstance(code, str) or len(code) != 6:
            return False
        
        # åªæ¥å—æœ‰æ•ˆçš„Aè‚¡ä»£ç 
        valid_first_digits = {'6', '0', '3', '8', '4'}
        if code[0] not in valid_first_digits:
            logger.debug(f"âŒ æ— æ•ˆä»£ç  {code}ï¼ˆç¬¬ä¸€ä½æ˜¯{code[0]}ï¼Œä¸æ˜¯Aè‚¡ä»£ç ï¼‰")
            return False
        
        # ç¡®ä¿åé¢éƒ½æ˜¯æ•°å­—
        if not code[1:].isdigit():
            logger.debug(f"âŒ æ— æ•ˆä»£ç  {code}ï¼ˆåŒ…å«éæ•°å­—å­—ç¬¦ï¼‰")
            return False
        
        # ç‰¹æ®Šæ‹’ç»åˆ—è¡¨ï¼ˆé”™è¯¯æ•°æ®ï¼‰
        invalid_prefixes = ['920', '921', '922']
        if any(code.startswith(prefix) for prefix in invalid_prefixes):
            logger.warning(f"âŒ æ‹’ç»é”™è¯¯ä»£ç  {code}ï¼ˆé”™è¯¯å‰ç¼€ï¼‰")
            return False
        
        return True
    
    def get_stock_list(self) -> List[Dict]:
        """
        è·å–Aè‚¡å…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨ - å¤šæ•°æ®æºè¡¥å…¨æœºåˆ¶
        
        ä¼˜å…ˆçº§é¡ºåºï¼š
        1. AkShareï¼ˆæœ€å¯é ï¼‰
        2. å·¨æ½®èµ„è®¯ç½‘é¡µçˆ¬è™«
        3. åŒèŠ±é¡ºç½‘é¡µçˆ¬è™«
        4. ä¸œæ–¹è´¢å¯ŒAPI
        5. å…¶ä»–å¤‡ç”¨æ–¹æ¡ˆ
        """

        # ä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜å±‚è¯»å–ï¼ˆé¿å…ç½‘ç»œè°ƒç”¨ï¼‰
        if self.local_cache_enabled and self.stock_cache_store:
            try:
                cached_stocks = self.stock_cache_store.load(force=False)
                if cached_stocks:
                    logger.info(f"âœ… è‚¡ç¥¨åˆ—è¡¨å·²ä»æœ¬åœ°ç¼“å­˜åŠ è½½: {len(cached_stocks)}åª")
                    # å…¼å®¹ä¸‹æ¸¸é€»è¾‘ï¼šè¡¥é½industryå­—æ®µ
                    return [
                        {**s, 'industry': s.get('industry') or 'æœªçŸ¥'}
                        for s in cached_stocks
                    ]
            except Exception as e:
                logger.debug(f"è¯»å–è‚¡ç¥¨æœ¬åœ°ç¼“å­˜å¤±è´¥ï¼Œå°†èµ°ç½‘ç»œè·å–: {e}")

        try:
            logger.info("="*80)
            logger.info("ğŸš€ å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨å®Œæ•´åˆ—è¡¨ - å¤šæ•°æ®æºè¡¥å…¨æœºåˆ¶")
            logger.info("="*80)
            
            all_stocks = {}  # code -> stock_infoï¼ˆå»é‡ï¼‰
            
            # å®šä¹‰æ•°æ®æºä¼˜å…ˆçº§ï¼ˆä»æœ€å¯é åˆ°å¤‡ç”¨ï¼‰
            sources = [
                ('è…¾è®¯è´¢ç»API', self._get_stock_list_from_tencent),
                ('ç½‘æ˜“è´¢ç»CSV', self._get_stock_list_from_netease_csv),
                ('AkShare', self._get_stock_list_from_akshare),
                ('å·¨æ½®èµ„è®¯çˆ¬è™«', self._get_stock_list_from_cninfo_crawler),
                ('åŒèŠ±é¡ºçˆ¬è™«', self._get_stock_list_from_ths_crawler),
                ('ä¸œæ–¹è´¢å¯ŒAPI', self._get_stock_list_from_eastmoney),
                ('å…¶ä»–å¤‡ç”¨æº', self._get_stock_list_backup),
            ]
            
            # å°è¯•å„æ•°æ®æº
            for source_name, fetch_func in sources:
                try:
                    logger.info(f"\n{'â”€'*60}")
                    logger.info(f"ğŸ” å°è¯•æ•°æ®æº: {source_name}")
                    logger.info(f"{'â”€'*60}")
                    
                    stocks = fetch_func()
                    
                    if not stocks:
                        logger.warning(f"âŒ [{source_name}] æœªè·å–åˆ°æ•°æ®ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæº...")
                        continue
                    
                    # éªŒè¯ä»£ç æ ¼å¼å¹¶å»é‡
                    valid_count = 0
                    invalid_count = 0
                    for stock in stocks:
                        code = stock.get('code', '')
                        if self.validate_stock_code(code):
                            if code not in all_stocks:
                                all_stocks[code] = stock
                                valid_count += 1
                        else:
                            invalid_count += 1
                    
                    logger.info(f"âœ… [{source_name}] æ–°å¢ {valid_count} ä¸ªæœ‰æ•ˆè‚¡ç¥¨")
                    if invalid_count > 0:
                        logger.warning(f"âš ï¸  [{source_name}] è¿‡æ»¤æ‰ {invalid_count} ä¸ªæ— æ•ˆä»£ç ")
                    logger.info(f"ğŸ“Š å½“å‰æ€»è®¡: {len(all_stocks)} ä¸ªè‚¡ç¥¨")
                    
                    # å¦‚æœå·²è·å–è¶³å¤Ÿæ•°æ®ï¼Œåœæ­¢
                    if len(all_stocks) >= 5000:
                        logger.info(f"\nğŸ‰ å·²è·å– {len(all_stocks)} ä¸ªè‚¡ç¥¨ï¼Œè¾¾åˆ°ç›®æ ‡ï¼")
                        break
                    
                except Exception as e:
                    logger.error(f"âŒ [{source_name}] è·å–å¤±è´¥: {e}")
                    continue
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            stock_list = list(all_stocks.values())
            
            if stock_list:
                logger.info(f"\n{'='*80}")
                logger.info(f"âœ… è‚¡ç¥¨åˆ—è¡¨è·å–å®Œæˆï¼æ€»è®¡è·å– {len(stock_list)} åªè‚¡ç¥¨")
                logger.info(f"{'='*80}")
                
                # éªŒè¯å’Œç»Ÿè®¡è‚¡ç¥¨åˆ—è¡¨
                self._validate_and_report_stock_list(stock_list)

                # å†™å…¥æœ¬åœ°ç¼“å­˜å±‚ï¼ˆç”¨äºåç»­å‰ç¼€æŸ¥è¯¢/å¿«é€Ÿå¯åŠ¨ï¼‰
                self._save_stock_cache(stock_list)
            else:
                logger.warning("âš ï¸ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º")
                stock_list = self._generate_demo_stock_list()
            
            return stock_list
                
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            # è¿”å›æ¼”ç¤ºæ•°æ®
            return self._generate_demo_stock_list()
    
    def _validate_and_report_stock_list(self, stocks: List[Dict]):
        """éªŒè¯å¹¶ç»Ÿè®¡è‚¡ç¥¨åˆ—è¡¨çš„å®Œæ•´æ€§"""
        if not stocks:
            logger.warning("âš ï¸ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
            return
        
        # æå–ä»£ç 
        codes = [stock['code'] for stock in stocks if stock['code']]
        if not codes:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return
        
        # ç»Ÿè®¡å„ç±»å‹ä»£ç 
        code_6 = sum(1 for c in codes if c.startswith('6'))
        code_0 = sum(1 for c in codes if c.startswith('0'))
        code_3 = sum(1 for c in codes if c.startswith('3'))
        code_8 = sum(1 for c in codes if c.startswith('8'))
        code_4 = sum(1 for c in codes if c.startswith('4'))
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š è‚¡ç¥¨åˆ—è¡¨ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   æ€»æ•°é‡: {len(stocks)} åª")
        logger.info(f"   6å¼€å¤´ï¼ˆæ²ªæ·±ä¸»æ¿ï¼‰: {code_6} åª")
        logger.info(f"   0å¼€å¤´ï¼ˆæ·±åœ³ä¸»æ¿ï¼‰: {code_0} åª")
        logger.info(f"   3å¼€å¤´ï¼ˆåˆ›ä¸šæ¿ï¼‰: {code_3} åª")
        logger.info(f"   8å¼€å¤´ï¼ˆåŒ—äº¤æ‰€ï¼‰: {code_8} åª")
        logger.info(f"   4å¼€å¤´ï¼ˆåŒ—äº¤æ‰€ï¼‰: {code_4} åª")
        logger.info(f"{'='*60}")
        
        # éªŒè¯æ•°é‡
        if len(stocks) >= 5000:
            logger.info(f"âœ… è‚¡ç¥¨æ•°é‡è¶³å¤Ÿï¼ˆ>= 5000ï¼‰")
        else:
            logger.warning(f"âš ï¸ è­¦å‘Š: è‚¡ç¥¨æ•°é‡ {len(stocks)} å°‘äºç›®æ ‡ 5000")
        
        # æ˜¾ç¤ºè‚¡ç¥¨ä»£ç èŒƒå›´
        min_code = min(codes)
        max_code = max(codes)
        logger.info(f"ğŸ“ˆ è‚¡ç¥¨ä»£ç èŒƒå›´: {min_code} - {max_code}")
    
    def _get_stock_list_from_tencent(self) -> List[Dict]:
        """
        ä»è…¾è®¯è´¢ç»APIè·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæœ€ç¨³å®šå¯é ï¼‰
        
        è…¾è®¯è´¢ç»APIé€šå¸¸æ¯”è¾ƒç¨³å®šï¼Œè€Œä¸”æ•°æ®å®Œæ•´
        """
        try:
            logger.info("æ­£åœ¨ä»è…¾è®¯è´¢ç»APIè·å–è‚¡ç¥¨åˆ—è¡¨...")
            
            stock_list = []
            
            # è…¾è®¯è´¢ç»çš„è‚¡ç¥¨åˆ—è¡¨API
            # åˆ†ä¸ºæ²ªå¸‚(sh)å’Œæ·±å¸‚(sz)
            markets = [
                ('sh', 'ä¸Šæµ·'),
                ('sz', 'æ·±åœ³'),
            ]
            
            for market_code, market_name in markets:
                try:
                    logger.info(f"æ­£åœ¨è·å–{market_name}è‚¡ç¥¨...")
                    
                    # è…¾è®¯è´¢ç»è‚¡ç¥¨åˆ—è¡¨æ¥å£
                    url = f"http://qt.gtimg.cn/q={market_code}000001"
                    
                    # å®é™…ä¸Šï¼Œè…¾è®¯è´¢ç»æœ‰ä¸€ä¸ªæ›´å¥½çš„æ¥å£
                    # æˆ‘ä»¬ä½¿ç”¨è‚¡ç¥¨åˆ—è¡¨çš„JSONæ ¼å¼
                    list_url = f"http://qt.gtimg.cn/q=s_{market_code}all"
                    
                    response = self._make_request(list_url)
                    if not response:
                        logger.warning(f"{market_name}è¯·æ±‚å¤±è´¥")
                        continue
                    
                    # è§£æè¿”å›æ•°æ®
                    text = response.text
                    
                    # è…¾è®¯è¿”å›æ ¼å¼: v_s_shall="sh600000~æµ¦å‘é“¶è¡Œ~..."
                    # æå–è‚¡ç¥¨ä»£ç 
                    import re
                    
                    # åŒ¹é…æ‰€æœ‰è‚¡ç¥¨ä»£ç 
                    pattern = rf'{market_code}(\d{{6}})'
                    matches = re.findall(pattern, text)
                    
                    logger.info(f"{market_name}æ‰¾åˆ°{len(matches)}ä¸ªåŒ¹é…")
                    
                    for code in matches:
                        full_code = code  # 6ä½ä»£ç 
                        if len(full_code) == 6:
                            stock_info = {
                                'code': full_code,
                                'name': '',  # åç§°éœ€è¦åç»­æŸ¥è¯¢
                                'industry': '',
                                'market': market_name
                            }
                            stock_list.append(stock_info)
                    
                except Exception as market_error:
                    logger.warning(f"{market_name}è·å–å¤±è´¥: {market_error}")
                    continue
            
            # å¦‚æœè…¾è®¯çš„ç¬¬ä¸€ä¸ªæ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¦ä¸€ä¸ªæ¥å£
            if len(stock_list) < 100:
                logger.info("å°è¯•è…¾è®¯è´¢ç»å¤‡ç”¨æ¥å£...")
                
                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨è…¾è®¯çš„æ¿å—æ•°æ®
                for page in range(1, 200):  # æœ€å¤š200é¡µ
                    try:
                        url = "http://stock.gtimg.cn/data/index.php"
                        params = {
                            'appn': 'rank',
                            't': 'ranka/chr',
                            'p': page,
                            'o': 0,
                            'l': 40,
                            'v': 'list_data'
                        }
                        
                        response = self._make_request(url, params=params)
                        if not response:
                            break
                        
                        try:
                            data = response.json()
                            if not data or 'data' not in data:
                                break
                            
                            items = data['data']
                            if not items:
                                break
                            
                            for item in items:
                                code = item.get('code', '')
                                name = item.get('name', '')
                                
                                if len(code) == 6 and code.isdigit():
                                    stock_info = {
                                        'code': code,
                                        'name': name,
                                        'industry': '',
                                        'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                                    }
                                    stock_list.append(stock_info)
                            
                            logger.info(f"ç¬¬{page}é¡µ: æ–°å¢{len(items)}åªï¼Œç´¯è®¡{len(stock_list)}åª")
                            
                            if len(stock_list) >= 5000:
                                break
                            
                        except:
                            break
                    
                    except:
                        break
            
            if stock_list:
                logger.info(f"âœ… ä»è…¾è®¯è´¢ç»è·å– {len(stock_list)} åªè‚¡ç¥¨")
            else:
                logger.warning("âŒ è…¾è®¯è´¢ç»æœªè·å–åˆ°æ•°æ®")
            
            return stock_list
            
        except Exception as e:
            logger.error(f"è…¾è®¯è´¢ç»è·å–å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_from_netease_csv(self) -> List[Dict]:
        """
        ä»ç½‘æ˜“è´¢ç»CSVæ•°æ®è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆéå¸¸å¯é ï¼‰
        
        ç½‘æ˜“è´¢ç»æä¾›CSVæ ¼å¼çš„è‚¡ç¥¨æ•°æ®ä¸‹è½½ï¼Œæ ¼å¼ç¨³å®š
        """
        try:
            logger.info("æ­£åœ¨ä»ç½‘æ˜“è´¢ç»CSVè·å–è‚¡ç¥¨åˆ—è¡¨...")
            
            import io
            
            stock_list = []
            
            # ç½‘æ˜“è´¢ç»æä¾›çš„Aè‚¡è‚¡ç¥¨åˆ—è¡¨CSV
            # æ²ªå¸‚
            urls = [
                ('http://quotes.money.163.com/service/chddata.html?code=0000001&start=19900101&end=20991231&fields=TCLOSE', 'æ²ªå¸‚'),
                ('http://quotes.money.163.com/service/chddata.html?code=1000001&start=19900101&end=20991231&fields=TCLOSE', 'æ·±å¸‚'),
            ]
            
            # ä½¿ç”¨ç½‘æ˜“çš„è‚¡ç¥¨åˆ—è¡¨APIï¼ˆåˆ†é¡µï¼‰
            for page in range(0, 100):  # æœ€å¤š100é¡µ
                try:
                    url = f"http://quotes.money.163.com/hs/service/diyrank.php"
                    params = {
                        'page': page,
                        'count': 5000,
                        'type': 'query',
                        'fields': 'SYMBOL,NAME,PRICE',
                        'query': 'STYPE:EQA',
                        'sort': 'SYMBOL',
                        'order': 'asc'
                    }
                    
                    response = self._make_request(url, params=params)
                    if not response:
                        if page == 0:
                            logger.warning("ç½‘æ˜“è´¢ç»è¯·æ±‚å¤±è´¥")
                            break
                        else:
                            logger.info(f"å·²è·å–{page}é¡µæ•°æ®ï¼Œåœæ­¢")
                            break
                    
                    # ç½‘æ˜“è¿”å›CSVæ ¼å¼
                    try:
                        df = pd.read_csv(io.StringIO(response.text))
                        
                        if df is None or len(df) == 0:
                            logger.info(f"ç¬¬{page}é¡µæ— æ•°æ®")
                            break
                        
                        for idx, row in df.iterrows():
                            try:
                                symbol = str(row.get('SYMBOL', ''))
                                name = str(row.get('NAME', ''))
                                
                                # è§£æä»£ç ï¼ˆç½‘æ˜“æ ¼å¼å¯èƒ½æ˜¯0600000æˆ–1000001ï¼‰
                                if symbol.startswith('0') or symbol.startswith('1'):
                                    code = symbol[1:]  # å»æ‰ç¬¬ä¸€ä½
                                else:
                                    code = symbol
                                
                                if len(code) == 6 and code.isdigit():
                                    stock_info = {
                                        'code': code,
                                        'name': name,
                                        'industry': '',
                                        'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                                    }
                                    stock_list.append(stock_info)
                            except:
                                continue
                        
                        logger.info(f"ç¬¬{page}é¡µ: è·å–{len(df)}æ¡ï¼Œç´¯è®¡{len(stock_list)}åª")
                        
                        if len(stock_list) >= 5000:
                            logger.info("å·²è·å–è¶³å¤Ÿæ•°æ®")
                            break
                        
                    except Exception as parse_error:
                        logger.debug(f"ç¬¬{page}é¡µè§£æå¤±è´¥: {parse_error}")
                        if page == 0:
                            break
                        else:
                            break
                    
                except Exception as page_error:
                    logger.debug(f"ç¬¬{page}é¡µè·å–å¤±è´¥: {page_error}")
                    break
            
            if stock_list:
                logger.info(f"âœ… ä»ç½‘æ˜“è´¢ç»CSVè·å– {len(stock_list)} åªè‚¡ç¥¨")
            else:
                logger.warning("âŒ ç½‘æ˜“è´¢ç»CSVæœªè·å–åˆ°æ•°æ®")
            
            return stock_list
            
        except Exception as e:
            logger.error(f"ç½‘æ˜“è´¢ç»CSVè·å–å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_from_akshare(self) -> List[Dict]:
        """
        ä»AkShareè·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆæœ€æ¨èçš„æ–¹æ¡ˆï¼‰
        
        ä¼˜ç‚¹ï¼š
        - å¼€æºå…è´¹ï¼Œæ— éœ€æ³¨å†Œ
        - æ•°æ®å®Œæ•´å‡†ç¡®ï¼ˆæ”¯æŒ5000+è‚¡ç¥¨ï¼‰
        - ä¸æ˜“è¢«é™æµ
        - æ¥å£ç¨³å®š
        
        æ³¨æ„ï¼šå¦‚æœç½‘ç»œä¸ç¨³å®šå¯èƒ½ä¼šå¤±è´¥ï¼Œä½†æœ‰å…¶ä»–å¤‡ç”¨æ•°æ®æº
        """
        try:
            logger.info("æ­£åœ¨ä»AkShareè·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            
            try:
                import akshare as ak
            except ImportError:
                logger.error("âŒ AkShareæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install akshare")
                return []
            
            stock_list = []
            
            # AkShareæä¾›å¤šä¸ªæ¥å£ï¼Œå°è¯•å¤šä¸ª
            methods = [
                ('stock_zh_a_spot_em', 'Aè‚¡å®æ—¶è¡Œæƒ…ï¼ˆä¸œæ–¹è´¢å¯Œï¼‰'),
                ('stock_info_a_code_name', 'Aè‚¡ä»£ç å’Œåç§°'),
                ('stock_zh_a_spot', 'Aè‚¡å®æ—¶è¡Œæƒ…ï¼ˆæ–°æµªï¼‰'),
            ]
            
            for method_name, desc in methods:
                try:
                    logger.info(f"å°è¯•AkShareæ–¹æ³•: {desc}...")
                    
                    if not hasattr(ak, method_name):
                        logger.debug(f"æ–¹æ³• {method_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                        continue
                    
                    method = getattr(ak, method_name)
                    df = method()
                    
                    if df is None or len(df) == 0:
                        logger.warning(f"{desc} è¿”å›ç©ºæ•°æ®")
                        continue
                    
                    logger.info(f"{desc} è¿”å› {len(df)} æ¡è®°å½•ï¼Œæ­£åœ¨è§£æ...")
                    
                    # è§£ææ•°æ®ï¼ˆå­—æ®µåå¯èƒ½ä¸åŒï¼‰
                    for idx, row in df.iterrows():
                        try:
                            # å°è¯•ä¸åŒçš„å­—æ®µå
                            code = str(row.get('ä»£ç ', row.get('code', row.get('symbol', ''))))
                            name = str(row.get('åç§°', row.get('name', '')))
                            
                            # ç¡®ä¿ä»£ç æ˜¯6ä½
                            if len(code) == 6 and code.isdigit():
                                stock_info = {
                                    'code': code,
                                    'name': name,
                                    'industry': '',
                                    'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                                }
                                stock_list.append(stock_info)
                        except Exception as e:
                            logger.debug(f"è§£æè¡Œå¤±è´¥: {e}")
                            continue
                    
                    if len(stock_list) >= 100:
                        logger.info(f"âœ… ä»AkShareæˆåŠŸè·å– {len(stock_list)} åªè‚¡ç¥¨")
                        return stock_list
                    
                except Exception as method_error:
                    logger.debug(f"{desc} å¼‚å¸¸: {method_error}")
                    # å³ä½¿æœ‰å¼‚å¸¸ï¼Œä¹Ÿæ£€æŸ¥æ˜¯å¦è·å–åˆ°äº†éƒ¨åˆ†æ•°æ®
                    if len(stock_list) >= 100:
                        logger.info(f"âœ… ä»AkShareè·å– {len(stock_list)} åªè‚¡ç¥¨ï¼ˆéƒ¨åˆ†æ–¹æ³•æˆåŠŸï¼‰")
                        return stock_list
                    continue
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œä½†è·å–åˆ°äº†ä¸€äº›æ•°æ®
            if stock_list:
                logger.info(f"âœ… ä»AkShareè·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨")
                return stock_list
            else:
                logger.warning("âŒ AkShareæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥")
                return []
            
        except Exception as e:
            logger.error(f"AkShareè·å–å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_from_cninfo_crawler(self) -> List[Dict]:
        """
        ä»å·¨æ½®èµ„è®¯ç½‘é¡µçˆ¬å–Aè‚¡ä¸Šå¸‚å…¬å¸åˆ—è¡¨
        
        å·¨æ½®èµ„è®¯æ˜¯ä¸­å›½è¯ç›‘ä¼šæŒ‡å®šçš„ä¿¡æ¯æŠ«éœ²ç½‘ç«™ï¼Œæ•°æ®æœ€æƒå¨
        """
        try:
            logger.info("æ­£åœ¨ä»å·¨æ½®èµ„è®¯çˆ¬å–è‚¡ç¥¨åˆ—è¡¨...")
            
            from bs4 import BeautifulSoup
            
            stock_list = []
            
            # å·¨æ½®èµ„è®¯çš„ä¸Šå¸‚å…¬å¸åˆ—è¡¨API
            url = "http://www.cninfo.com.cn/new/data/szse_stock.json"
            
            response = self._make_request(url)
            if not response:
                logger.warning("å·¨æ½®èµ„è®¯è¯·æ±‚å¤±è´¥")
                return []
            
            try:
                data = response.json()
                
                if isinstance(data, dict) and 'stockList' in data:
                    stock_data = data['stockList']
                elif isinstance(data, list):
                    stock_data = data
                else:
                    logger.warning("å·¨æ½®èµ„è®¯è¿”å›æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                    return []
                
                for item in stock_data:
                    code = item.get('code', '')
                    name = item.get('name', '') or item.get('orgCName', '')
                    
                    if code and name:
                        stock_info = {
                            'code': code,
                            'name': name,
                            'industry': '',
                            'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                        }
                        stock_list.append(stock_info)
                
                logger.info(f"âœ… ä»å·¨æ½®èµ„è®¯è·å– {len(stock_list)} åªè‚¡ç¥¨")
                return stock_list
                
            except Exception as e:
                logger.warning(f"å·¨æ½®èµ„è®¯æ•°æ®è§£æå¤±è´¥: {e}")
                return []
            
        except Exception as e:
            logger.error(f"å·¨æ½®èµ„è®¯çˆ¬è™«å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_from_ths_crawler(self) -> List[Dict]:
        """
        ä»åŒèŠ±é¡ºçˆ¬å–è‚¡ç¥¨åˆ—è¡¨
        
        åŒèŠ±é¡ºæ˜¯çŸ¥åçš„è´¢ç»æ•°æ®å¹³å°ï¼Œæ•°æ®æ¯”è¾ƒå®Œæ•´
        """
        try:
            logger.info("æ­£åœ¨ä»åŒèŠ±é¡ºçˆ¬å–è‚¡ç¥¨åˆ—è¡¨...")
            
            stock_list = []
            
            # åŒèŠ±é¡ºè‚¡ç¥¨åˆ—è¡¨API
            url = "http://q.10jqka.com.cn/index/index/board/all/field/zdf/order/desc/page/1/ajax/1/"
            
            response = self._make_request(
                url,
                referer='http://q.10jqka.com.cn/'
            )
            
            if not response:
                logger.warning("åŒèŠ±é¡ºè¯·æ±‚å¤±è´¥")
                return []
            
            try:
                from bs4 import BeautifulSoup
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # æŸ¥æ‰¾è‚¡ç¥¨è¡¨æ ¼
                table = soup.find('table', class_='m-table')
                if not table:
                    logger.warning("åŒèŠ±é¡ºæœªæ‰¾åˆ°è‚¡ç¥¨è¡¨æ ¼")
                    return []
                
                rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
                
                for row in rows:
                    try:
                        cols = row.find_all('td')
                        if len(cols) >= 3:
                            code = cols[1].text.strip()
                            name = cols[2].text.strip()
                            
                            if code and name:
                                stock_info = {
                                    'code': code,
                                    'name': name,
                                    'industry': '',
                                    'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                                }
                                stock_list.append(stock_info)
                    except:
                        continue
                
                logger.info(f"âœ… ä»åŒèŠ±é¡ºè·å– {len(stock_list)} åªè‚¡ç¥¨")
                
                # åŒèŠ±é¡ºå•é¡µæ•°æ®è¾ƒå°‘ï¼Œå¦‚æœæœ‰éœ€è¦å¯ä»¥åˆ†é¡µ
                # ä½†ä½œä¸ºå¤‡ç”¨æºï¼Œå°‘é‡æ•°æ®ä¹Ÿå¯ä»¥æ¥å—
                return stock_list
                
            except Exception as e:
                logger.warning(f"åŒèŠ±é¡ºæ•°æ®è§£æå¤±è´¥: {e}")
                return []
            
        except Exception as e:
            logger.error(f"åŒèŠ±é¡ºçˆ¬è™«å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_from_eastmoney(self) -> List[Dict]:
        """ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¸¦åçˆ¬è™«å¤„ç†å’Œå®Œæ•´åˆ†é¡µï¼‰"""
        try:
            url = "https://push2.eastmoney.com/api/qt/clist/get"
            page_size = 100  # æ¯é¡µ100åªè‚¡ç¥¨
            stock_list = []
            total_stocks = 0
            current_page = 1
            consecutive_empty_pages = 0
            
            # APIå‚æ•°é…ç½®
            params = {
                'pz': page_size,
                'po': 1,
                'np': 1,
                'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
                'fltt': 2,
                'invt': 2,
                'fid': 'f3',
                'fs': 'm:0 t:6,m:0 t:80,m:1 t:2,m:1 t:23',  # Aè‚¡å…¨éƒ¨è‚¡ç¥¨
                'fields': 'f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152'
            }
            
            logger.info("ğŸ” å¼€å§‹ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨...")
            logger.info(f"ğŸ“Š ä½¿ç”¨åçˆ¬è™«ç­–ç•¥: User-Agentè½®æ¢ + éšæœºå»¶è¿Ÿ + æŒ‡æ•°é€€é¿")
            
            # ä½¿ç”¨è¿›åº¦æ¡
            pbar = None
            
            while True:
                try:
                    # æ›´æ–°é¡µç 
                    params['pn'] = current_page
                    
                    # ä½¿ç”¨å¸¦åçˆ¬è™«çš„è¯·æ±‚æ–¹æ³•
                    logger.debug(f"æ­£åœ¨è·å–ç¬¬{current_page}é¡µæ•°æ®...")
                    response = self._make_request(
                        url, 
                        params=params, 
                        referer='https://quote.eastmoney.com/center/gridlist.html'
                    )
                    
                    if not response:
                        logger.warning(f"ç¬¬{current_page}é¡µè¯·æ±‚å¤±è´¥ï¼Œå°è¯•ç»§ç»­...")
                        consecutive_empty_pages += 1
                        if consecutive_empty_pages >= 3:
                            logger.error(f"è¿ç»­{consecutive_empty_pages}é¡µè¯·æ±‚å¤±è´¥ï¼Œåœæ­¢è·å–")
                            break
                        current_page += 1
                        continue
                    
                    # å°è¯•è§£æJSON
                    try:
                        data = response.json()
                    except Exception as json_error:
                        logger.warning(f"ç¬¬{current_page}é¡µJSONè§£æå¤±è´¥ï¼Œå°è¯•ç»§ç»­: {json_error}")
                        consecutive_empty_pages += 1
                        if consecutive_empty_pages >= 3:
                            logger.error(f"è¿ç»­{consecutive_empty_pages}é¡µè§£æå¤±è´¥ï¼Œåœæ­¢è·å–")
                            break
                        current_page += 1
                        continue
                    
                    # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
                    consecutive_empty_pages = 0
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
                    if not data.get('data') or not data['data'].get('diff'):
                        logger.info(f"ç¬¬{current_page}é¡µæ— æ•°æ®ï¼Œåœæ­¢è·å–")
                        break
                    
                    current_page_stocks = data['data']['diff']
                    page_stock_count = 0
                    
                    # ç¬¬ä¸€é¡µæ—¶è·å–æ€»æ•°å¹¶åˆå§‹åŒ–è¿›åº¦æ¡
                    if current_page == 1:
                        total_stocks = data['data'].get('total', 0)
                        logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ°æ€»è‚¡ç¥¨æ•°é‡: {total_stocks}åª")
                        if total_stocks > 0:
                            pbar = tqdm(total=total_stocks, desc="è·å–è‚¡ç¥¨åˆ—è¡¨", unit="åª")
                    
                    # è§£æè‚¡ç¥¨æ•°æ®
                    for item in current_page_stocks:
                        stock_info = {
                            'code': item.get('f12', ''),
                            'name': item.get('f14', ''),
                            'industry': '',
                            'market': 'ä¸Šæµ·' if item.get('f13') == '1' else 'æ·±åœ³'
                        }
                        if stock_info['code'] and stock_info['name']:
                            stock_list.append(stock_info)
                            page_stock_count += 1
                            if pbar:
                                pbar.update(1)
                    
                    logger.info(f"âœ… ç¬¬{current_page}é¡µ: è·å–{page_stock_count}åªè‚¡ç¥¨ï¼Œç´¯è®¡{len(stock_list)}åª")
                    
                    # åˆ¤æ–­æ˜¯å¦å·²è·å–æ‰€æœ‰æ•°æ®
                    if len(stock_list) >= total_stocks or len(current_page_stocks) < page_size:
                        logger.info("âœ… å·²è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®")
                        break
                    
                    # é˜²æ­¢æ— é™å¾ªç¯ï¼ˆæ”¯æŒæœ€å¤š100é¡µ = 10000åªè‚¡ç¥¨ï¼Œè¶³ä»¥è¦†ç›–å…¨éƒ¨5000+ï¼‰
                    if current_page > 100:
                        logger.warning("âš ï¸ è¾¾åˆ°é¡µæ•°é™åˆ¶(100é¡µ)ï¼Œåœæ­¢è·å–")
                        break
                    
                    current_page += 1
                    
                except KeyboardInterrupt:
                    logger.warning("ç”¨æˆ·ä¸­æ–­è·å–")
                    break
                    
                except Exception as e:
                    logger.error(f"ç¬¬{current_page}é¡µå¤„ç†å¼‚å¸¸: {e}")
                    consecutive_empty_pages += 1
                    if consecutive_empty_pages >= 3:
                        logger.error(f"è¿ç»­å¼‚å¸¸{consecutive_empty_pages}æ¬¡ï¼Œåœæ­¢è·å–")
                        break
                    current_page += 1
            
            if pbar:
                pbar.close()
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            logger.info(f"ğŸ“Š ä¸œæ–¹è´¢å¯Œç½‘è·å–å®Œæˆ:")
            logger.info(f"   - æ€»è¯·æ±‚æ•°: {self.request_count}")
            logger.info(f"   - å¤±è´¥è¯·æ±‚: {self.failed_request_count}")
            logger.info(f"   - é‡è¯•æ¬¡æ•°: {self.retry_count}")
            logger.info(f"   - è·å–è‚¡ç¥¨: {len(stock_list)}åª")
            
            return stock_list
            
        except Exception as e:
            logger.error(f"ä¸œæ–¹è´¢å¯Œç½‘è·å–å¤±è´¥: {e}")
            return []
    
    def _get_stock_list_backup(self) -> List[Dict]:
        """å¤‡ç”¨è‚¡ç¥¨åˆ—è¡¨è·å–æ–¹æ³• - ä½¿ç”¨å¤šä¸ªæ•°æ®æº"""
        try:
            all_stocks = {}
            
            # æ–¹æ¡ˆ1: å°è¯•ä½¿ç”¨tushare
            logger.info("ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æº1: tushare...")
            try:
                import tushare as ts
                
                logger.info("æ­£åœ¨ä»tushareè·å–è‚¡ç¥¨åˆ—è¡¨...")
                stock_basic = ts.get_stock_basics()
                
                if stock_basic is not None and len(stock_basic) > 0:
                    for code, row in stock_basic.iterrows():
                        stock_info = {
                            'code': code,
                            'name': row.get('name', ''),
                            'industry': row.get('industry', 'æœªçŸ¥'),
                            'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                        }
                        if code not in all_stocks:
                            all_stocks[code] = stock_info
                    
                    logger.info(f"âœ… ä»tushareè·å–åˆ°{len(stock_basic)}åªè‚¡ç¥¨")
                    if len(all_stocks) >= 5000:
                        return list(all_stocks.values())
                
            except ImportError:
                logger.warning("tushareæ¨¡å—æœªå®‰è£…æˆ–æ— æ³•å¯¼å…¥")
            except Exception as e:
                logger.warning(f"tushareè·å–å¤±è´¥: {e}")
            
            # æ–¹æ¡ˆ2: å°è¯•ä½¿ç”¨æ–°æµªè´¢ç»çš„è‚¡ç¥¨åˆ—è¡¨APIï¼ˆåˆ†é¡µï¼‰
            logger.info("ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æº2: æ–°æµªè´¢ç»ï¼ˆåˆ†é¡µè·å–ï¼‰...")
            try:
                url = "http://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/Market_Center.getHQNodeData"
                
                # åˆ†é¡µè·å–æ‰€æœ‰æ•°æ®
                page = 1
                while True:
                    params = {
                        'page': page,
                        'num': 500,  # æ¯é¡µ500æ¡
                        'sort': 'symbol',
                        'asc': 1,
                        'node': 'hs_a',
                        'symbol': '',
                        '_s_r_a': 'page'
                    }
                    
                    response = self._make_request(url, params=params)
                    if not response:
                        logger.warning(f"ç¬¬{page}é¡µè¯·æ±‚å¤±è´¥")
                        break
                    
                    try:
                        data = response.json()
                    except:
                        logger.warning(f"ç¬¬{page}é¡µJSONè§£æå¤±è´¥")
                        break
                    
                    if not data or not isinstance(data, list):
                        logger.info(f"ç¬¬{page}é¡µæ— æ•°æ®ï¼Œåœæ­¢åˆ†é¡µè·å–")
                        break
                    
                    page_count = 0
                    for item in data:
                        code = item.get('code', '')
                        if code and code not in all_stocks:
                            stock_info = {
                                'code': code,
                                'name': item.get('name', ''),
                                'industry': item.get('industry', 'æœªçŸ¥'),
                                'market': 'ä¸Šæµ·' if code.startswith('6') else 'æ·±åœ³'
                            }
                            all_stocks[code] = stock_info
                            page_count += 1
                    
                    logger.info(f"âœ… ç¬¬{page}é¡µ: è·å–{page_count}åªè‚¡ç¥¨ï¼Œæ€»è®¡{len(all_stocks)}åª")
                    
                    if len(data) < 500:
                        logger.info("å·²è·å–æ‰€æœ‰æ•°æ®ï¼ˆæœ€åä¸€é¡µæ•°æ®ä¸è¶³500æ¡ï¼‰")
                        break
                    
                    if page > 20:  # é™åˆ¶æœ€å¤š20é¡µï¼ˆ10000æ¡ï¼‰
                        logger.warning("è¾¾åˆ°åˆ†é¡µé™åˆ¶")
                        break
                    
                    page += 1
                    
                if len(all_stocks) >= 5000:
                    logger.info(f"âœ… ä»æ–°æµªè´¢ç»è·å–åˆ°{len(all_stocks)}åªè‚¡ç¥¨")
                    return list(all_stocks.values())
                        
            except Exception as e:
                logger.warning(f"æ–°æµªè´¢ç»è·å–å¤±è´¥: {e}")
            
            # å¦‚æœè·å–äº†ä¸€äº›è‚¡ç¥¨ï¼Œè¿”å›
            if all_stocks:
                logger.info(f"âœ… ä»å¤‡ç”¨æ•°æ®æºè·å–åˆ°{len(all_stocks)}åªè‚¡ç¥¨")
                return list(all_stocks.values())
            
            # æ‰€æœ‰å¤‡ç”¨æ–¹æ¡ˆéƒ½å¤±è´¥
            logger.warning("æ‰€æœ‰å¤‡ç”¨æ•°æ®æºéƒ½æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return []
            
        except Exception as e:
            logger.error(f"å¤‡ç”¨æ•°æ®æºè·å–å¤±è´¥: {e}")
            return []
    
    def _generate_demo_stock_list(self) -> List[Dict]:
        """ç”Ÿæˆæ¼”ç¤ºç”¨è‚¡ç¥¨åˆ—è¡¨"""
        logger.info("ç”Ÿæˆæ¼”ç¤ºç”¨è‚¡ç¥¨åˆ—è¡¨...")
        
        demo_stocks = [
            {'code': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'æ·±åœ³'},
            {'code': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§', 'market': 'æ·±åœ³'},
            {'code': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’', 'market': 'æ·±åœ³'},
            {'code': '600036', 'name': 'æ‹›å•†é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸Šæµ·'},
            {'code': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’', 'market': 'ä¸Šæµ·'},
            {'code': '600887', 'name': 'ä¼Šåˆ©è‚¡ä»½', 'industry': 'ä¹³ä¸š', 'market': 'ä¸Šæµ·'},
            {'code': '000725', 'name': 'äº¬ä¸œæ–¹A', 'industry': 'æ˜¾ç¤ºé¢æ¿', 'market': 'æ·±åœ³'},
            {'code': '300059', 'name': 'ä¸œæ–¹è´¢å¯Œ', 'industry': 'é‡‘èç§‘æŠ€', 'market': 'æ·±åœ³'},
            {'code': '002415', 'name': 'æµ·åº·å¨è§†', 'industry': 'å®‰é˜²ç›‘æ§', 'market': 'æ·±åœ³'},
            {'code': '300750', 'name': 'å®å¾·æ—¶ä»£', 'industry': 'é”‚ç”µæ± ', 'market': 'æ·±åœ³'}
        ]
        
        return demo_stocks
    
    def _load_industry_cache(self):
        """åŠ è½½è¡Œä¸šåˆ†ç±»ç¼“å­˜ã€‚

        ä¼˜å…ˆçº§ï¼š
        1) local_cache/industries.*ï¼ˆSQLite + pickleï¼Œå¸¦TTL/ç‰ˆæœ¬ç®¡ç†ï¼‰
        2) æ—§ç‰ˆ cache/industry/shenwan_industry_mapping.pklï¼ˆå…¼å®¹å†å²è·¯å¾„ï¼‰
        """
        try:
            if self.local_cache_enabled and self.industry_cache_store:
                mapping = self.industry_cache_store.as_fetcher_cache_mapping()
                if mapping:
                    self.industry_cache.clear()
                    self.industry_cache.update(mapping)
                    logger.info(
                        f"âœ… æœ¬åœ°ç¼“å­˜å±‚è¡Œä¸šåˆ†ç±»å·²åŠ è½½ï¼ŒåŒ…å« {len(self.industry_cache)} ä¸ªè‚¡ç¥¨çš„åˆ†ç±»ä¿¡æ¯"
                    )
                    return

            if not INDUSTRY_CACHE_CONFIG.get('enabled'):
                return

            cache_dir = INDUSTRY_CACHE_CONFIG.get('cache_dir', './cache/industry')
            cache_file = os.path.join(cache_dir, INDUSTRY_CACHE_CONFIG.get('cache_file', 'shenwan_industry_mapping.pkl'))

            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    cached_data = pickle.load(f)
                    if isinstance(cached_data, dict) and 'mapping' in cached_data:
                        cache_time = cached_data.get('timestamp', 0)
                        cache_duration = INDUSTRY_CACHE_CONFIG.get('cache_duration', 7 * 24 * 3600)
                        if time.time() - cache_time < cache_duration:
                            self.industry_cache.clear()
                            self.industry_cache.update(cached_data.get('mapping', {}))
                            logger.info(
                                f"âœ… è¡Œä¸šåˆ†ç±»æ—§ç¼“å­˜å·²åŠ è½½ï¼ŒåŒ…å« {len(self.industry_cache)} ä¸ªè‚¡ç¥¨çš„åˆ†ç±»ä¿¡æ¯"
                            )
                            return
                        else:
                            logger.info("âš ï¸ è¡Œä¸šåˆ†ç±»æ—§ç¼“å­˜å·²è¿‡æœŸï¼Œå°†é‡æ–°è·å–")
                            os.remove(cache_file)
        except Exception as e:
            logger.warning(f"åŠ è½½è¡Œä¸šåˆ†ç±»ç¼“å­˜å¤±è´¥: {e}")
    
    def _save_industry_cache(self):
        """ä¿å­˜è¡Œä¸šåˆ†ç±»æ˜ å°„åˆ°ç¼“å­˜æ–‡ä»¶ã€‚

        ä¼˜å…ˆä¿å­˜åˆ° local_cacheï¼ˆSQLite + pickleï¼‰ï¼Œå¹¶å…¼å®¹å†™å›æ—§ç‰ˆpklç¼“å­˜ã€‚
        """
        try:
            if not self.industry_cache:
                return

            if not self._local_cache_dirty:
                return

            # 1) æ–°æœ¬åœ°ç¼“å­˜å±‚
            if self.local_cache_enabled and self.industry_cache_store:
                if not self._local_cache_backup_timestamp:
                    self._local_cache_backup_timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')

                create_backup = not self._local_cache_backup_done
                self.industry_cache_store.save(
                    self.industry_cache,
                    version=LOCAL_CACHE_CONFIG.get('default_version'),
                    create_backup=create_backup,
                    backup_timestamp=self._local_cache_backup_timestamp,
                )
                self._local_cache_backup_done = True

            # 2) æ—§ç‰ˆç¼“å­˜ï¼ˆä¿æŒå†å²å…¼å®¹æ€§ï¼‰
            if not INDUSTRY_CACHE_CONFIG.get('enabled'):
                self._local_cache_dirty = False
                return

            cache_dir = INDUSTRY_CACHE_CONFIG.get('cache_dir', './cache/industry')
            os.makedirs(cache_dir, exist_ok=True)

            cache_file = os.path.join(cache_dir, INDUSTRY_CACHE_CONFIG.get('cache_file', 'shenwan_industry_mapping.pkl'))

            cache_data = {
                'timestamp': time.time(),
                'mapping': self.industry_cache
            }

            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            logger.debug(f"è¡Œä¸šåˆ†ç±»æ—§ç¼“å­˜å·²ä¿å­˜: {cache_file}")

            self._local_cache_dirty = False
        except Exception as e:
            logger.warning(f"ä¿å­˜è¡Œä¸šåˆ†ç±»ç¼“å­˜å¤±è´¥: {e}")

    def _save_stock_cache(self, stocks: List[Dict]):
        """ä¿å­˜è‚¡ç¥¨åˆ—è¡¨åˆ°æœ¬åœ°ç¼“å­˜å±‚ï¼ˆlocal_cacheï¼‰ã€‚"""
        try:
            if not stocks:
                return
            if not (self.local_cache_enabled and self.stock_cache_store):
                return

            if not self._local_cache_backup_timestamp:
                self._local_cache_backup_timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')

            create_backup = not self._local_cache_backup_done
            self.stock_cache_store.save(
                stocks,
                version=LOCAL_CACHE_CONFIG.get('default_version'),
                create_backup=create_backup,
                backup_timestamp=self._local_cache_backup_timestamp,
            )
            self._local_cache_backup_done = True
        except Exception as e:
            logger.warning(f"ä¿å­˜è‚¡ç¥¨ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_shenwan_industry_from_tushare(self, stock_code: str) -> Optional[Dict]:
        """ä»tushareè·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»"""
        try:
            import tushare as ts
            
            # æ£€æŸ¥ç¼“å­˜
            if stock_code in self.industry_cache:
                return self.industry_cache[stock_code]
            
            # è§„èŒƒåŒ–è‚¡ç¥¨ä»£ç ï¼ˆtushareéœ€è¦å®Œæ•´çš„TSä»£ç ï¼‰
            ts_code = stock_code
            if stock_code.startswith('6'):
                ts_code = stock_code + '.SH'
            else:
                ts_code = stock_code + '.SZ'
            
            logger.debug(f"ä»tushareè·å– {stock_code} çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»...")
            
            # è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯
            industry_df = ts.get_stock_info()
            if industry_df is not None and len(industry_df) > 0:
                # æŸ¥æ‰¾å¯¹åº”çš„è‚¡ç¥¨
                stock_row = industry_df[industry_df['ts_code'] == ts_code]
                if len(stock_row) > 0:
                    row = stock_row.iloc[0]
                    industry_info = {
                        'shenwan_level1': row.get('shenwan_level1', ''),
                        'shenwan_level2': row.get('shenwan_level2', ''),
                        'shenwan_level3': row.get('shenwan_level3', ''),
                        'industry': row.get('industry', ''),
                        'source': 'tushare'
                    }
                    self.industry_cache[stock_code] = industry_info
                    return industry_info
            
            return None
            
        except Exception as e:
            logger.debug(f"tushareè·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def _get_shenwan_industry_from_eastmoney(self, stock_code: str, stock_name: str) -> Optional[Dict]:
        """ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»ï¼ˆé€šè¿‡è¯¦æƒ…é¡µè§£æï¼‰"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            if stock_code in self.industry_cache:
                return self.industry_cache[stock_code]
            
            code_with_market = stock_code
            if stock_code.startswith('6'):
                code_with_market = '1.' + stock_code
            else:
                code_with_market = '0.' + stock_code
            
            url = f"https://push2.eastmoney.com/api/qt/stock/get"
            params = {
                'secid': code_with_market,
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'fields': 'f57,f58,f100,f101,f102,f103'
            }
            
            logger.debug(f"ä»ä¸œæ–¹è´¢å¯Œè·å– {stock_code} çš„è¡Œä¸šä¿¡æ¯...")
            
            response = self._make_request(
                url,
                params=params,
                referer='https://quote.eastmoney.com'
            )
            
            if not response:
                return None
            
            data = response.json()
            if data.get('data'):
                result = data['data']
                industry_info = {
                    'shenwan_level1': result.get('f100', ''),
                    'shenwan_level2': result.get('f101', ''),
                    'shenwan_level3': result.get('f102', ''),
                    'industry': result.get('f57', ''),
                    'source': 'eastmoney'
                }
                self.industry_cache[stock_code] = industry_info
                return industry_info
            
            return None
            
        except Exception as e:
            logger.debug(f"ä¸œæ–¹è´¢å¯Œè·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def _get_shenwan_industry_from_sina(self, stock_code: str, stock_name: str) -> Optional[Dict]:
        """ä»æ–°æµªè´¢ç»è·å–è¡Œä¸šåˆ†ç±»"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            if stock_code in self.industry_cache:
                return self.industry_cache[stock_code]
            
            code_with_market = stock_code
            if stock_code.startswith('6'):
                code_with_market = 'sh' + stock_code
            else:
                code_with_market = 'sz' + stock_code
            
            url = f"https://hq.sinajs.cn/"
            params = {
                'list': code_with_market
            }
            
            logger.debug(f"ä»æ–°æµªè´¢ç»è·å– {stock_code} çš„è¡Œä¸šä¿¡æ¯...")
            
            response = self._make_request(
                url,
                params=params,
                referer='https://finance.sina.com.cn'
            )
            
            if not response:
                return None
            
            # æ–°æµªè¿”å›çš„æ˜¯ç‰¹æ®Šæ ¼å¼ï¼Œéœ€è¦è§£æ
            try:
                text = response.text
                # å°è¯•ä»HTMLæˆ–JSONä¸­æå–è¡Œä¸šä¿¡æ¯
                if 'industry' in text.lower():
                    # è¿™é‡Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘
                    # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œè¿”å›Noneè®©ç³»ç»Ÿå°è¯•å…¶ä»–æ–¹å¼
                    logger.debug("æ–°æµªè´¢ç»è¿”å›çš„æ•°æ®éœ€è¦ç‰¹æ®Šè§£æï¼Œæš‚æ—¶è·³è¿‡")
            except:
                pass
            
            return None
            
        except Exception as e:
            logger.debug(f"æ–°æµªè´¢ç»è·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def get_shenwan_industry(self, stock_code: str, stock_name: str) -> Dict:
        """è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»ï¼ˆå¤šæ•°æ®æº + æ™ºèƒ½è¡¥å…¨ + ç¼“å­˜ï¼‰ã€‚"""
        try:
            before = self.industry_cache.get(stock_code)
            before_valid = bool(before and self.industry_fetcher.is_cache_entry_valid(before))

            result = self.industry_fetcher.get_industry(stock_code, stock_name, "")

            after = self.industry_cache.get(stock_code)
            after_valid = bool(after and self.industry_fetcher.is_cache_entry_valid(after))
            if after_valid and not before_valid:
                self._local_cache_dirty = True

            return result
        except Exception as e:
            logger.error(f"è·å–{stock_code}è¡Œä¸šåˆ†ç±»è¿‡ç¨‹å‡ºé”™: {e}")
            return {
                'shenwan_level1': 'é”™è¯¯',
                'shenwan_level2': 'é”™è¯¯',
                'shenwan_level3': 'é”™è¯¯',
                'industry': 'é”™è¯¯',
                'source': 'error',
            }
    
    def search_real_estate_data(self, stock_code: str, stock_name: str) -> Dict:
        """
        æœç´¢ç‰¹å®šè‚¡ç¥¨çš„éç»è¥æ€§æˆ¿åœ°äº§æ•°æ®
        
        æ•°æ®æºä¼˜å…ˆçº§ï¼š
        1. å·¨æ½®èµ„è®¯ (cninfo) - å®˜æ–¹æ•°æ®æº
        2. ä¸œæ–¹è´¢å¯Œ (eastmoney) - éœ€è¦åçˆ¬è™«å¤„ç†
        3. æ–°æµªè´¢ç» (sina) - å¤‡é€‰æ–¹æ¡ˆ
        """
        result = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'real_estate_2023': None,
            'real_estate_2024': None
        }
        
        try:
            # æŒ‰ä¼˜å…ˆçº§å°è¯•ä»å¤šä¸ªæ•°æ®æºè·å–æ•°æ®
            # ä¼˜å…ˆçº§ï¼šcninfo > eastmoney > sina
            data_sources = [
                ('cninfo', self._get_data_from_cninfo),
                ('eastmoney', self._get_data_from_eastmoney),
                ('sina', self._get_data_from_sina),
            ]
            
            for source_name, data_source in data_sources:
                # æ£€æŸ¥æ•°æ®æºæ˜¯å¦å¯ç”¨
                if not DATA_SOURCES.get(source_name, {}).get('enabled', False):
                    continue
                
                try:
                    data = data_source(stock_code, stock_name)
                    if data:
                        result.update(data)
                        logger.debug(f"ä»{source_name}è·å–åˆ°{stock_code}æ•°æ®")
                        break
                except Exception as e:
                    logger.debug(f"æ•°æ®æº{source_name}è·å–å¤±è´¥: {e}")
                    continue
            
            # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥ä»çœŸå®APIè·å–ï¼‰
            if result['real_estate_2023'] is None:
                result['real_estate_2023'] = self._generate_mock_data(stock_code, '2023')
            if result['real_estate_2024'] is None:
                result['real_estate_2024'] = self._generate_mock_data(stock_code, '2024')
            
            # è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»
            industry_info = self.get_shenwan_industry(stock_code, stock_name)
            result.update(industry_info)
                
        except Exception as e:
            logger.error(f"æœç´¢è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}")
            
        return result
    
    def _generate_mock_data(self, stock_code: str, year: str) -> float:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥åˆ é™¤ï¼‰"""
        import random
        # åŸºäºè‚¡ç¥¨ä»£ç ç”Ÿæˆä¼ªéšæœºä½†ä¸€è‡´çš„æ•°å€¼
        seed = int(stock_code[-3:]) + int(year)
        random.seed(seed)
        return round(random.uniform(1000000, 100000000), 2)
    
    def _get_data_from_eastmoney(self, stock_code: str, stock_name: str) -> Optional[Dict]:
        """ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–æ•°æ®ï¼ˆå¸¦åçˆ¬è™«å¤„ç†ï¼‰"""
        try:
            # æ„å»ºä¸œæ–¹è´¢å¯Œç½‘URL
            code_with_market = stock_code
            if stock_code.startswith('6'):
                code_with_market = '1.' + stock_code  # ä¸Šæµ·
            else:
                code_with_market = '0.' + stock_code  # æ·±åœ³
            
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                'secid': code_with_market,
                'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
                'fields1': 'f1,f2,f3,f4,f5,f6',
                'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58',
                'klt': '101',  # æ—¥Kçº¿
                'fqt': '1',
                'end': '20241231',
                'lmt': '120'
            }
            
            response = self._make_request(
                url, 
                params=params, 
                referer='https://quote.eastmoney.com'
            )
            
            if not response:
                return None
            
            data = response.json()
            
            if data.get('data') and data['data'].get('klines'):
                klines = data['data']['klines']
                # æŸ¥æ‰¾2023å¹´æœ«å’Œ2024å¹´æœ«æ•°æ®
                for kline in klines:
                    if kline.startswith('2023-12-31'):
                        # è§£æ2023å¹´æ•°æ®
                        parts = kline.split(',')
                        if len(parts) > 8:
                            return {
                                'real_estate_2023': float(parts[8]) if parts[8] else 0
                            }
                    elif kline.startswith('2024-12-31'):
                        # è§£æ2024å¹´æ•°æ®
                        parts = kline.split(',')
                        if len(parts) > 8:
                            return {
                                'real_estate_2024': float(parts[8]) if parts[8] else 0
                            }
            
            return None
            
        except Exception as e:
            logger.debug(f"ä¸œæ–¹è´¢å¯Œç½‘æ•°æ®è·å–å¤±è´¥: {e}")
            return None
    
    def _get_data_from_sina(self, stock_code: str, stock_name: str) -> Optional[Dict]:
        """ä»æ–°æµªè´¢ç»è·å–æ•°æ®"""
        try:
            # æ–°æµªè´¢ç»æ•°æ®è·å–é€»è¾‘
            code_with_market = stock_code
            if stock_code.startswith('6'):
                code_with_market = 'sh' + stock_code
            else:
                code_with_market = 'sz' + stock_code
            
            url = f"https://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData"
            params = {
                'symbol': code_with_market,
                'scale': 240,
                'ma': 'no',
                'datalen': '120'
            }
            
            response = self.session.get(url, params=params, timeout=15)
            data = response.json()
            
            if data:
                result = {}
                for item in data:
                    if item.get('day') in ['2023-12-31', '2024-12-31']:
                        if item['day'] == '2023-12-31':
                            result['real_estate_2023'] = float(item.get('low', 0))
                        elif item['day'] == '2024-12-31':
                            result['real_estate_2024'] = float(item.get('low', 0))
                
                return result if result else None
            
            return None
            
        except Exception as e:
            logger.debug(f"æ–°æµªè´¢ç»æ•°æ®è·å–å¤±è´¥: {e}")
            return None
    
    def _get_data_from_cninfo(self, stock_code: str, stock_name: str) -> Optional[Dict]:
        """ä»å·¨æ½®èµ„è®¯ç½‘è·å–æ•°æ®"""
        try:
            # å·¨æ½®èµ„è®¯ç½‘æ•°æ®è·å–é€»è¾‘
            # è¿™é‡Œéœ€è¦å®é™…çš„å·¨æ½®èµ„è®¯ç½‘APIè°ƒç”¨
            
            # æ¨¡æ‹Ÿå®ç°
            logger.debug(f"å°è¯•ä»å·¨æ½®èµ„è®¯ç½‘è·å– {stock_code} æ•°æ®")
            return None
            
        except Exception as e:
            logger.debug(f"å·¨æ½®èµ„è®¯ç½‘æ•°æ®è·å–å¤±è´¥: {e}")
            return None
    
    def clean_and_validate_data(self, data: List[Dict]) -> List[Dict]:
        """æ•°æ®æ¸…æ´—å’ŒéªŒè¯"""
        logger.info("å¼€å§‹æ•°æ®æ¸…æ´—å’ŒéªŒè¯...")
        
        cleaned_data = []
        seen_codes = set()
        
        for item in data:
            try:
                # æ•°æ®éªŒè¯
                if not item.get('stock_code') or not item.get('stock_name'):
                    continue
                
                # å»é‡
                if item['stock_code'] in seen_codes:
                    continue
                seen_codes.add(item['stock_code'])
                
                # æ•°å€¼éªŒè¯å’Œæ¸…æ´—
                if item.get('real_estate_2023'):
                    item['real_estate_2023'] = float(item['real_estate_2023'])
                    if item['real_estate_2023'] < 0:
                        item['real_estate_2023'] = 0
                else:
                    item['real_estate_2023'] = 0
                
                if item.get('real_estate_2024'):
                    item['real_estate_2024'] = float(item['real_estate_2024'])
                    if item['real_estate_2024'] < 0:
                        item['real_estate_2024'] = 0
                else:
                    item['real_estate_2024'] = 0
                
                cleaned_data.append(item)
                
            except Exception as e:
                logger.warning(f"æ•°æ®æ¸…æ´—å¤±è´¥ {item}: {e}")
                continue
        
        logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆï¼Œä»{len(data)}æ¡è®°å½•æ¸…æ´—ä¸º{len(cleaned_data)}æ¡æœ‰æ•ˆè®°å½•")
        return cleaned_data
    
    def export_to_excel(self, data: List[Dict], filename: str = None) -> str:
        """å¯¼å‡ºæ•°æ®åˆ°Excelæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"Aè‚¡éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§_2023-2024_{timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
                # åŸå§‹æ•°æ®è¡¨
                df_raw = pd.DataFrame(data)
                df_raw.to_excel(writer, sheet_name='åŸå§‹æ•°æ®', index=False)
                
                # å¤„ç†åæ•°æ®è¡¨
                processed_data = []
                for item in data:
                    processed_data.append({
                        'è‚¡ç¥¨ä»£ç ': item.get('stock_code', ''),
                        'è‚¡ç¥¨åç§°': item.get('stock_name', ''),
                        '2023å¹´æœ«éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§(å…ƒ)': item.get('real_estate_2023', 0),
                        '2024å¹´æœ«éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§(å…ƒ)': item.get('real_estate_2024', 0),
                        'èµ„äº§å˜åŒ–(å…ƒ)': item.get('real_estate_2024', 0) - item.get('real_estate_2023', 0),
                        'å˜åŒ–ç‡(%)': round(((item.get('real_estate_2024', 0) - item.get('real_estate_2023', 0)) / max(item.get('real_estate_2023', 1), 1)) * 100, 2),
                        'ç”³ä¸‡ä¸€çº§è¡Œä¸š': item.get('shenwan_level1', ''),
                        'ç”³ä¸‡äºŒçº§è¡Œä¸š': item.get('shenwan_level2', ''),
                        'ç”³ä¸‡ä¸‰çº§è¡Œä¸š': item.get('shenwan_level3', ''),
                        'ç”³ä¸‡è¡Œä¸šæ¥æº': item.get('source', ''),
                        'é€šç”¨è¡Œä¸šåˆ†ç±»': item.get('industry', ''),
                        'å¸‚åœº': item.get('market', '')
                    })
                
                df_processed = pd.DataFrame(processed_data)
                df_processed.to_excel(writer, sheet_name='å¤„ç†åæ•°æ®', index=False)
                
                # æ•°æ®ç»Ÿè®¡è¡¨
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': [
                        'æ€»è‚¡ç¥¨æ•°é‡',
                        '2023å¹´æœ‰éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§çš„å…¬å¸æ•°',
                        '2024å¹´æœ‰éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§çš„å…¬å¸æ•°',
                        '2023å¹´æ€»èµ„äº§(å…ƒ)',
                        '2024å¹´æ€»èµ„äº§(å…ƒ)',
                        'å¹³å‡èµ„äº§(2023å¹´)',
                        'å¹³å‡èµ„äº§(2024å¹´)'
                    ],
                    'æ•°å€¼': [
                        len(data),
                        len([x for x in data if x.get('real_estate_2023', 0) > 0]),
                        len([x for x in data if x.get('real_estate_2024', 0) > 0]),
                        sum([x.get('real_estate_2023', 0) for x in data]),
                        sum([x.get('real_estate_2024', 0) for x in data]),
                        sum([x.get('real_estate_2023', 0) for x in data]) / len(data) if data else 0,
                        sum([x.get('real_estate_2024', 0) for x in data]) / len(data) if data else 0
                    ]
                }
                
                df_stats = pd.DataFrame(stats_data)
                df_stats.to_excel(writer, sheet_name='æ•°æ®ç»Ÿè®¡', index=False)
                
                # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨å¯¹è±¡ç”¨äºæ ¼å¼åŒ–
                workbook = writer.book
                worksheet1 = writer.sheets['åŸå§‹æ•°æ®']
                worksheet2 = writer.sheets['å¤„ç†åæ•°æ®']
                worksheet3 = writer.sheets['æ•°æ®ç»Ÿè®¡']
                
                # æ·»åŠ æ ¼å¼
                header_format = workbook.add_format({
                    'bold': True,
                    'text_wrap': True,
                    'valign': 'top',
                    'fg_color': '#D7E4BC',
                    'border': 1
                })
                
                number_format = workbook.add_format({'num_format': '#,##0.00'})
                percentage_format = workbook.add_format({'num_format': '0.00%'})
                
                # æ ¼å¼åŒ–å„å·¥ä½œè¡¨
                for sheet_name, worksheet in [('åŸå§‹æ•°æ®', worksheet1), ('å¤„ç†åæ•°æ®', worksheet2)]:
                    for col_num, value in enumerate(df_raw.columns if sheet_name == 'åŸå§‹æ•°æ®' else df_processed.columns):
                        worksheet.write(0, col_num, value, header_format)
                    
                    # è®¾ç½®åˆ—å®½
                    for i, col in enumerate(df_raw.columns if sheet_name == 'åŸå§‹æ•°æ®' else df_processed.columns):
                        worksheet.set_column(i, i, 15)
                
                # æ ¼å¼åŒ–ç»Ÿè®¡è¡¨
                for col_num, value in enumerate(df_stats.columns):
                    worksheet3.write(0, col_num, value, header_format)
                worksheet3.set_column(0, 0, 25)
                worksheet3.set_column(1, 1, 20)
                
            logger.info(f"æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°Excelæ–‡ä»¶: {filename}")
            return os.path.abspath(filename)
            
        except Exception as e:
            logger.error(f"Excelæ–‡ä»¶å¯¼å‡ºå¤±è´¥: {e}")
            raise
    
    def run(self, max_stocks: int = 100):
        """
        æ‰§è¡Œæ•°æ®æ”¶é›†ä¸»æµç¨‹
        
        Args:
            max_stocks: æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°é‡ï¼Œ0è¡¨ç¤ºå¤„ç†å…¨éƒ¨
        """
        logger.info("="*60)
        logger.info("å¼€å§‹Aè‚¡éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§æ•°æ®æ”¶é›†...")
        logger.info(f"åçˆ¬è™«æªæ–½: User-Agentè½®æ¢ + éšæœºå»¶è¿Ÿ + æŒ‡æ•°é€€é¿")
        logger.info("="*60)
        start_time = time.time()
        
        try:
            # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
            print("\n" + "="*60)
            print("ğŸ” ç¬¬1æ­¥ï¼šè·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨")
            print("="*60)
            stock_list = self.get_stock_list()
            if not stock_list:
                logger.error("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œç¨‹åºé€€å‡º")
                return None
            
            # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            original_count = len(stock_list)
            if max_stocks > 0:
                stock_list = stock_list[:max_stocks]
                print(f"\nğŸ“ æµ‹è¯•æ¨¡å¼ï¼šä»{original_count}åªè‚¡ç¥¨ä¸­é€‰æ‹©å‰{max_stocks}åªè¿›è¡Œå¤„ç†")
            else:
                print(f"\nğŸš€ å®Œæ•´æ¨¡å¼ï¼šå°†å¤„ç†å…¨éƒ¨{original_count}åªè‚¡ç¥¨")
            
            print(f"âœ… è‚¡ç¥¨åˆ—è¡¨å‡†å¤‡å®Œæˆï¼Œå°†å¤„ç†{len(stock_list)}åªè‚¡ç¥¨\n")
            
            # 2. å¤šæºå¾ªç¯è¡¥å…¨è¡Œä¸šåˆ†ç±»
            print("="*60)
            print("ğŸ·ï¸ ç¬¬2æ­¥ï¼šå¤šæºå¾ªç¯è¡¥å…¨ç”³ä¸‡è¡Œä¸šåˆ†ç±»")
            print("="*60)
            try:
                # å…ˆç”¨ç¼“å­˜å‘½ä¸­ï¼ˆé¿å…ç½‘ç»œè°ƒç”¨ï¼‰
                cached_for_run: Dict[str, Dict] = {}
                for s in stock_list:
                    code = s.get('code')
                    if not code:
                        continue
                    cached = self.industry_cache.get(code)
                    if cached and cached.get('source') not in {'unknown', 'error'}:
                        cached_for_run[code] = cached

                missing_stocks = [s for s in stock_list if s.get('code') and s.get('code') not in cached_for_run]

                if cached_for_run:
                    print(f"ğŸ—„ï¸  å·²ä»ç¼“å­˜å‘½ä¸­è¡Œä¸šåˆ†ç±»: {len(cached_for_run)}/{len(stock_list)}")

                fetched: Dict[str, Dict] = {}
                if missing_stocks:
                    # ä½¿ç”¨æ–°çš„å¤šæºå¾ªç¯è¡¥å…¨è·å–å™¨ï¼Œä»…è·å–ç¼ºå¤±éƒ¨åˆ†
                    complete_getter = IndustryClassificationCompleteGetter(logger=logger)
                    fetched = complete_getter.get_complete_classification(missing_stocks, show_progress=True)

                industries_dict: Dict[str, Dict] = {**cached_for_run, **(fetched or {})}

                # è¡¥é½æœªè¿”å›çš„è‚¡ç¥¨
                for s in stock_list:
                    code = s.get('code')
                    if code and code not in industries_dict:
                        industries_dict[code] = {
                            'shenwan_level1': '',
                            'shenwan_level2': '',
                            'shenwan_level3': '',
                            'industry': '',
                            'source': 'unknown',
                        }

                total = len(industries_dict)
                success = len([v for v in industries_dict.values() if v.get('source') not in {'unknown', 'error'}])

                # æ›´æ–°ç¼“å­˜ï¼ˆin-placeï¼Œä¿æŒfetcherå¼•ç”¨ä¸å˜ï¼‰
                self.industry_cache.update(industries_dict)
                if missing_stocks:
                    self._local_cache_dirty = True
                    self._save_industry_cache()

                print(f"âœ… è¡Œä¸šåˆ†ç±»å‡†å¤‡å®Œæˆï¼š{success}/{total} åªè‚¡ç¥¨è·å¾—æœ‰æ•ˆåˆ†ç±»")
                print(f"ğŸ“Š è¦†ç›–ç‡: {success/total*100:.1f}%")

            except Exception as e:
                logger.warning(f"å¤šæºå¾ªç¯è¡¥å…¨è¡Œä¸šåˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ—§çš„è·å–å™¨ï¼ˆåŒæ ·åªå¤„ç†ç¼ºå¤±éƒ¨åˆ†ï¼‰
                missing_stocks = [s for s in stock_list if s.get('code') and s.get('code') not in self.industry_cache]
                fetched = self.industry_fetcher.batch_get_industries(missing_stocks)
                industries_dict = {**self.industry_cache, **(fetched or {})}

                total = len([s for s in stock_list if s.get('code')])
                success = len([
                    code for code in industries_dict
                    if code in {s.get('code') for s in stock_list}
                    and industries_dict.get(code, {}).get('source') not in {'unknown', 'error'}
                ])

                self.industry_cache.update(industries_dict)
                if fetched:
                    self._local_cache_dirty = True
                    self._save_industry_cache()

                print(f"âœ… å¤‡ç”¨æ–¹æ¡ˆå®Œæˆï¼š{success}/{total} åªè‚¡ç¥¨è·å¾—æœ‰æ•ˆåˆ†ç±»")

            # 3. é€ä¸ªè·å–è‚¡ç¥¨æ•°æ®
            print("="*60)
            print("ğŸ” ç¬¬3æ­¥ï¼šè·å–æˆ¿åœ°äº§èµ„äº§æ•°æ®")
            print("="*60)
            all_data = []
            
            # è®¡ç®—é¢„è®¡å®Œæˆæ—¶é—´
            avg_delay = sum(REQUEST_CONFIG['delay_between_requests']) / 2 if isinstance(REQUEST_CONFIG['delay_between_requests'], tuple) else REQUEST_CONFIG['delay_between_requests']
            estimated_time = len(stock_list) * avg_delay
            print(f"â±ï¸ é¢„è®¡éœ€è¦æ—¶é—´: {estimated_time/60:.1f}åˆ†é’Ÿ ({estimated_time:.0f}ç§’)")
            print(f"ğŸ“Š å¹³å‡æ¯åªè‚¡ç¥¨å»¶è¿Ÿ: {avg_delay:.2f}ç§’\n")
            
            # ä½¿ç”¨è¿›åº¦æ¡
            with tqdm(total=len(stock_list), desc="å¤„ç†è‚¡ç¥¨æ•°æ®", unit="åª") as pbar:
                for i, stock in enumerate(stock_list):
                    try:
                        data = self.search_real_estate_data(stock['code'], stock['name'])
                        stock_basic = {k: v for k, v in stock.items() if k != 'industry'}
                        data.update(stock_basic)
                        all_data.append(data)
                        
                        pbar.set_postfix({
                            'å½“å‰': f"{stock['code']} {stock['name'][:6]}",
                            'æˆåŠŸ': len(all_data),
                            'è¯·æ±‚': self.request_count
                        })
                        pbar.update(1)
                        
                    except Exception as e:
                        logger.warning(f"è·å–è‚¡ç¥¨ {stock['code']} æ•°æ®å¤±è´¥: {e}")
                        pbar.update(1)
                        continue
                    
                    # æ¯500ä¸ªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœï¼ˆå¦‚æœå¤„ç†å¤§é‡æ•°æ®ï¼‰
                    if (i + 1) % 500 == 0 and len(stock_list) > 500:
                        print(f"\nğŸ’¾ å·²å¤„ç† {i+1} åªè‚¡ç¥¨ï¼Œä¿å­˜ä¸­é—´ç»“æœ...")
                        try:
                            temp_data = self.clean_and_validate_data(all_data)
                            temp_file = f"temp_result_{i+1}.xlsx"
                            self.export_to_excel(temp_data, temp_file)
                            print(f"âœ… ä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {temp_file}\n")
                        except Exception as e:
                            logger.warning(f"ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")
            
            print(f"\nâœ… è‚¡ç¥¨æ•°æ®è·å–å®Œæˆï¼Œå…±è·å–{len(all_data)}åªè‚¡ç¥¨çš„æœ‰æ•ˆæ•°æ®")
            
            # æ˜¾ç¤ºè¯·æ±‚ç»Ÿè®¡
            print("\n" + "="*60)
            print("ğŸ“Š è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯")
            print("="*60)
            print(f"æ€»è¯·æ±‚æ•°: {self.request_count}")
            print(f"å¤±è´¥è¯·æ±‚: {self.failed_request_count}")
            print(f"é‡è¯•æ¬¡æ•°: {self.retry_count}")
            if self.request_count > 0:
                success_rate = (1 - self.failed_request_count / self.request_count) * 100
                print(f"æˆåŠŸç‡: {success_rate:.1f}%")
            
            # 4. æ•°æ®æ¸…æ´—å’ŒéªŒè¯
            print("\n" + "="*60)
            print("ğŸ§¹ ç¬¬4æ­¥ï¼šæ•°æ®æ¸…æ´—å’ŒéªŒè¯")
            print("="*60)
            cleaned_data = self.clean_and_validate_data(all_data)
            print(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®{len(cleaned_data)}æ¡")
            
            # 5. å¯¼å‡ºåˆ°Excel
            print("\n" + "="*60)
            print("ğŸ“Š ç¬¬5æ­¥ï¼šå¯¼å‡ºExcelæ–‡ä»¶")
            print("="*60)
            output_file = self.export_to_excel(cleaned_data)
            
            # ä¿å­˜è¡Œä¸šåˆ†ç±»ç¼“å­˜
            print("\nğŸ’¾ ä¿å­˜è¡Œä¸šåˆ†ç±»ç¼“å­˜...")
            self._save_industry_cache()
            print(f"âœ… è¡Œä¸šåˆ†ç±»ç¼“å­˜å·²ä¿å­˜ï¼ŒåŒ…å« {len(self.industry_cache)} ä¸ªè‚¡ç¥¨çš„åˆ†ç±»ä¿¡æ¯")
            
            # è®¡ç®—æ€»ç”¨æ—¶
            total_time = time.time() - start_time
            
            # æœ€ç»ˆç»Ÿè®¡
            print("\n" + "="*60)
            print("ğŸ‰ æ•°æ®æ”¶é›†å®Œæˆï¼")
            print("="*60)
            print(f"â° æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ ({total_time:.0f}ç§’)")
            print(f"ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(cleaned_data)}åª")
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"ğŸ“ˆ æ–‡ä»¶å¤§å°: {os.path.getsize(output_file)/1024:.1f} KB")
            print(f"ğŸ“‹ è¡Œä¸šåˆ†ç±»ç¼“å­˜: {len(self.industry_cache)} ä¸ªè‚¡ç¥¨")
            print("="*60)
            
            return output_file
            
        except Exception as e:
            logger.error(f"æ•°æ®æ”¶é›†è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ¢ Aè‚¡éç»è¥æ€§æˆ¿åœ°äº§èµ„äº§æ•°æ®è·å–è„šæœ¬ v2.1")
    print("=" * 70)
    print("âœ¨ æ–°ç‰¹æ€§:")
    print("   â€¢ å®Œæ•´è‚¡ç¥¨åˆ—è¡¨è·å– (5000+åªè‚¡ç¥¨)")
    print("   â€¢ åçˆ¬è™«å¤„ç† (User-Agentè½®æ¢ + éšæœºå»¶è¿Ÿ + æŒ‡æ•°é€€é¿)")
    print("   â€¢ ç”³ä¸‡è¡Œä¸šåˆ†ç±»è·å–å’Œå…³è”ï¼ˆå¤šæºè¡¥å…¨ï¼šä¸œæ–¹è´¢å¯Œè¡Œä¸šæ¿å—/æ–°æµªç”³ä¸‡/ä¸œæ–¹è´¢å¯ŒF10ç­‰ï¼‰")
    print("   â€¢ è¡Œä¸šåˆ†ç±»ç¼“å­˜æœºåˆ¶ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰")
    print("   â€¢ è¿›åº¦æ¡æ˜¾ç¤º")
    print("   â€¢ è¯¦ç»†çš„è¯·æ±‚ç»Ÿè®¡")
    print("   â€¢ Excelæ–‡ä»¶å¯¼å‡ºï¼ˆå«ç”³ä¸‡ä¸€äºŒä¸‰çº§è¡Œä¸šåˆ†ç±»ï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºæ•°æ®æ”¶é›†å™¨
    collector = AStockRealEstateDataCollector()
    
    # æ˜¾ç¤ºå¹¶å‘å’Œå¿«é€Ÿå¤±è´¥é…ç½®çŠ¶æ€
    from config import CONCURRENT_CONFIG, FAST_FAIL_CONFIG, SOURCE_SELECTION_CONFIG
    if CONCURRENT_CONFIG.get('enabled'):
        print(f"âš™ï¸  å¹¶å‘è·å–å·²å¯ç”¨ (çº¿ç¨‹æ•°: {CONCURRENT_CONFIG.get('max_workers', 5)}, æ‰¹å¤§å°: {CONCURRENT_CONFIG.get('batch_size', 100)})")
    if FAST_FAIL_CONFIG.get('enabled'):
        print(f"âš¡ å¿«é€Ÿå¤±è´¥ç­–ç•¥å·²å¯ç”¨ (è¶…æ—¶: {FAST_FAIL_CONFIG.get('request_timeout', 10)}ç§’, é‡è¯•: {FAST_FAIL_CONFIG.get('max_retries', 2)}æ¬¡)")
    if SOURCE_SELECTION_CONFIG.get('enabled'):
        print(f"ğŸ¯ æ™ºèƒ½æºé€‰æ‹©å·²å¯ç”¨ (æœ€å°æˆåŠŸç‡: {SOURCE_SELECTION_CONFIG.get('min_success_rate', 0.05)}, æœ€å¤§æºæ•°: {SOURCE_SELECTION_CONFIG.get('max_sources_per_stock', 3)})")
    print("=" * 70)
    
    try:
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å¤„ç†å…¨éƒ¨è‚¡ç¥¨è¿˜æ˜¯æµ‹è¯•æ¨¡å¼
        print("ğŸ“‹ è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. æµ‹è¯•æ¨¡å¼ (å¤„ç†10åªè‚¡ç¥¨)")
        print("2. å®Œæ•´æ¨¡å¼ (å¤„ç†å…¨éƒ¨è‚¡ç¥¨ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)")
        print("3. è‡ªå®šä¹‰æ•°é‡")
        
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nä½¿ç”¨é»˜è®¤æµ‹è¯•æ¨¡å¼...")
            choice = "1"
        
        if choice == "2":
            max_stocks = 0  # 0è¡¨ç¤ºå¤„ç†å…¨éƒ¨è‚¡ç¥¨
            print("ğŸš€ å·²é€‰æ‹©å®Œæ•´æ¨¡å¼ï¼Œå°†å¤„ç†å…¨éƒ¨è‚¡ç¥¨...")
        elif choice == "3":
            try:
                max_stocks = int(input("è¯·è¾“å…¥è¦å¤„ç†çš„è‚¡ç¥¨æ•°é‡: "))
                print(f"ğŸ“Š å°†å¤„ç†{max_stocks}åªè‚¡ç¥¨")
            except (ValueError, EOFError, KeyboardInterrupt):
                print("ä½¿ç”¨é»˜è®¤æµ‹è¯•æ¨¡å¼...")
                max_stocks = 10
        else:
            max_stocks = 10  # é»˜è®¤æµ‹è¯•æ¨¡å¼
            print("ğŸ§ª å·²é€‰æ‹©æµ‹è¯•æ¨¡å¼ï¼Œå°†å¤„ç†10åªè‚¡ç¥¨")
        
        print("\n" + "=" * 60)
        print("å¼€å§‹æ‰§è¡Œæ•°æ®æ”¶é›†...")
        print("=" * 60)
        
        # æ‰§è¡Œæ•°æ®æ”¶é›†
        output_file = collector.run(max_stocks=max_stocks)
        
        if output_file:
            print("\n" + "=" * 60)
            print("âœ… æ•°æ®æ”¶é›†æˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"ğŸ“Š å¤„ç†è‚¡ç¥¨æ•°é‡: æŸ¥çœ‹Excelæ–‡ä»¶ä¸­çš„ç»Ÿè®¡ä¿¡æ¯")
            print("=" * 60)
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            try:
                import os
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    print(f"ğŸ“ˆ æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
            except:
                pass
                
        else:
            print("\nâŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("ç¨‹åºå·²å®‰å…¨é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸: {e}")


if __name__ == "__main__":
    main()