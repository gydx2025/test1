#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–­ç‚¹ç»­ä¼ å’Œå¢é‡æ›´æ–°ç³»ç»Ÿ

æä¾›æ£€æŸ¥ç‚¹ç®¡ç†ã€å¢é‡æ›´æ–°ã€å˜æ›´è¿½è¸ªç­‰åŠŸèƒ½
"""

import json
import logging
import os
from typing import Dict, List, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)


class CheckpointManager:
    """æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, checkpoint_dir: str = 'checkpoints'):
        """
        åˆå§‹åŒ–æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        
        Args:
            checkpoint_dir: æ£€æŸ¥ç‚¹ç›®å½•
        """
        self.checkpoint_dir = checkpoint_dir
        os.makedirs(checkpoint_dir, exist_ok=True)
    
    def save_checkpoint(self, stage: str, progress: Dict):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹
        
        Args:
            stage: é˜¶æ®µåç§°ï¼ˆå¦‚'stock_list', 'industry', 'financial'ï¼‰
            progress: è¿›åº¦ä¿¡æ¯
        """
        try:
            checkpoint_file = os.path.join(
                self.checkpoint_dir, 
                f'checkpoint_{stage}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            )
            
            checkpoint_data = {
                'stage': stage,
                'timestamp': datetime.now().isoformat(),
                'progress': progress
            }
            
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def save_partial_results(self, stage: str, data: List[Dict], count: int):
        """
        ä¿å­˜éƒ¨åˆ†å¤„ç†ç»“æœï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
        
        Args:
            stage: é˜¶æ®µåç§°
            data: å·²å¤„ç†çš„æ•°æ®
            count: å¤„ç†è®¡æ•°
        """
        try:
            result_file = os.path.join(
                self.checkpoint_dir,
                f'partial_result_{stage}_{count}.json'
            )
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"éƒ¨åˆ†ç»“æœå·²ä¿å­˜: {result_file} ({len(data)}æ¡)")
            
        except Exception as e:
            logger.error(f"ä¿å­˜éƒ¨åˆ†ç»“æœå¤±è´¥: {e}")
    
    def get_latest_checkpoint(self, stage: str) -> Optional[Dict]:
        """
        è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹
        
        Args:
            stage: é˜¶æ®µåç§°
            
        Returns:
            æ£€æŸ¥ç‚¹æ•°æ®æˆ–None
        """
        try:
            files = [f for f in os.listdir(self.checkpoint_dir) 
                    if f.startswith(f'checkpoint_{stage}_')]
            
            if not files:
                logger.info(f"æœªæ‰¾åˆ°{stage}é˜¶æ®µçš„æ£€æŸ¥ç‚¹")
                return None
            
            # è·å–æœ€æ–°çš„æ–‡ä»¶
            latest_file = sorted(files)[-1]
            checkpoint_file = os.path.join(self.checkpoint_dir, latest_file)
            
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
            
            logger.info(f"å·²åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹: {checkpoint_file}")
            return checkpoint_data
            
        except Exception as e:
            logger.error(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None
    
    def resume_from_checkpoint(self, stage: str) -> Optional[Dict]:
        """
        ä»æ£€æŸ¥ç‚¹æ¢å¤
        
        Args:
            stage: é˜¶æ®µåç§°
            
        Returns:
            è¿›åº¦ä¿¡æ¯æˆ–None
        """
        checkpoint = self.get_latest_checkpoint(stage)
        if checkpoint:
            logger.info(f"ä»{checkpoint['timestamp']}æ¢å¤{stage}é˜¶æ®µ")
            return checkpoint.get('progress')
        return None
    
    def clear_checkpoints(self, stage: Optional[str] = None):
        """
        æ¸…ç©ºæ£€æŸ¥ç‚¹
        
        Args:
            stage: é˜¶æ®µåç§°ï¼ŒNoneè¡¨ç¤ºæ¸…ç©ºæ‰€æœ‰
        """
        try:
            if stage:
                files = [f for f in os.listdir(self.checkpoint_dir) 
                        if f.startswith(f'checkpoint_{stage}_')]
            else:
                files = os.listdir(self.checkpoint_dir)
            
            for file in files:
                os.remove(os.path.join(self.checkpoint_dir, file))
            
            logger.info(f"æ£€æŸ¥ç‚¹å·²æ¸…ç©º: {stage or 'å…¨éƒ¨'}")
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºæ£€æŸ¥ç‚¹å¤±è´¥: {e}")


class IncrementalUpdate:
    """å¢é‡æ›´æ–°ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, previous_data_file: Optional[str] = None):
        """
        åˆå§‹åŒ–å¢é‡æ›´æ–°ç®¡ç†å™¨
        
        Args:
            previous_data_file: å‰ä¸€æ¬¡é‡‡é›†çš„æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.previous_data_file = previous_data_file
        self.previous_data = {}
        self.load_previous_data()
    
    def load_previous_data(self):
        """åŠ è½½å‰ä¸€æ¬¡çš„æ•°æ®"""
        if self.previous_data_file and os.path.exists(self.previous_data_file):
            try:
                with open(self.previous_data_file, 'r', encoding='utf-8') as f:
                    self.previous_data = json.load(f)
                logger.info(f"å·²åŠ è½½å‰ä¸€æ¬¡æ•°æ®: {self.previous_data_file}")
            except Exception as e:
                logger.error(f"åŠ è½½å‰ä¸€æ¬¡æ•°æ®å¤±è´¥: {e}")
    
    def compare_stocks(self, current_stocks: List[Dict]) -> Dict:
        """
        æ¯”è¾ƒè‚¡ç¥¨åˆ—è¡¨å˜åŒ–
        
        Args:
            current_stocks: å½“å‰é‡‡é›†çš„è‚¡ç¥¨åˆ—è¡¨
            
        Returns:
            å˜åŒ–åˆ†æ
        """
        # æ„å»ºcodeé›†åˆ
        previous_codes = set(stock.get('code') for stock in self.previous_data.get('stocks', []))
        current_codes = set(stock.get('code') for stock in current_stocks)
        
        # è®¡ç®—å˜åŒ–
        new_stocks = current_codes - previous_codes
        delisted_stocks = previous_codes - current_codes
        unchanged_stocks = previous_codes & current_codes
        
        # è·å–æ–°ä¸Šå¸‚å’Œé€€å¸‚çš„è¯¦ç»†ä¿¡æ¯
        new_stock_details = [s for s in current_stocks if s.get('code') in new_stocks]
        
        return {
            'new_stocks': list(new_stocks),
            'new_stock_count': len(new_stocks),
            'new_stock_details': new_stock_details,
            'delisted_stocks': list(delisted_stocks),
            'delisted_stock_count': len(delisted_stocks),
            'unchanged_stocks': unchanged_stocks,
            'unchanged_stock_count': len(unchanged_stocks),
            'total_current': len(current_stocks),
            'total_previous': len(self.previous_data.get('stocks', []))
        }
    
    def compare_financial_data(self, current_data: List[Dict]) -> Dict:
        """
        æ¯”è¾ƒè´¢åŠ¡æ•°æ®å˜åŒ–
        
        Args:
            current_data: å½“å‰é‡‡é›†çš„è´¢åŠ¡æ•°æ®
            
        Returns:
            å˜åŒ–åˆ†æ
        """
        previous_data_map = {
            item['code']: item 
            for item in self.previous_data.get('financial', [])
        }
        
        updated_records = []
        unchanged_records = []
        
        for current_item in current_data:
            code = current_item.get('code')
            
            if code not in previous_data_map:
                # æ–°å¢
                updated_records.append({
                    'code': code,
                    'change': 'new',
                    'details': current_item
                })
            else:
                previous_item = previous_data_map[code]
                
                # æ¯”è¾ƒå…³é”®å­—æ®µæ˜¯å¦å˜åŒ–
                changed = False
                for year in ['2023', '2024']:
                    key = f'non_op_real_estate_{year}'
                    if current_item.get(key) != previous_item.get(key):
                        changed = True
                        break
                
                if changed:
                    updated_records.append({
                        'code': code,
                        'change': 'updated',
                        'previous': previous_item,
                        'current': current_item
                    })
                else:
                    unchanged_records.append(code)
        
        return {
            'updated_records': updated_records,
            'updated_count': len(updated_records),
            'unchanged_count': len(unchanged_records),
            'new_count': len([r for r in updated_records if r['change'] == 'new']),
            'modified_count': len([r for r in updated_records if r['change'] == 'updated'])
        }
    
    def generate_changelog(self, changes: Dict) -> str:
        """
        ç”Ÿæˆå˜æ›´æ—¥å¿—
        
        Args:
            changes: å˜æ›´ä¿¡æ¯
            
        Returns:
            å˜æ›´æ—¥å¿—æ–‡æœ¬
        """
        lines = []
        lines.append("=" * 70)
        lines.append("ğŸ“ æ•°æ®å˜æ›´æ—¥å¿—")
        lines.append("=" * 70)
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}")
        
        if 'stock_changes' in changes:
            stock_changes = changes['stock_changes']
            lines.append(f"\nğŸ“ˆ è‚¡ç¥¨åˆ—è¡¨å˜åŒ–:")
            lines.append(f"  â€¢ æ–°ä¸Šå¸‚: {stock_changes['new_stock_count']}å®¶")
            lines.append(f"  â€¢ é€€å¸‚: {stock_changes['delisted_stock_count']}å®¶")
            lines.append(f"  â€¢ ä¸å˜: {stock_changes['unchanged_stock_count']}å®¶")
            lines.append(f"  â€¢ æ€»æ•°: {stock_changes['total_previous']} â†’ {stock_changes['total_current']}")
            
            if stock_changes['new_stock_count'] > 0:
                lines.append(f"\n  ğŸ†• æ–°ä¸Šå¸‚å…¬å¸:")
                for stock in stock_changes['new_stock_details'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    lines.append(f"     - {stock.get('code')} {stock.get('name')}")
                if stock_changes['new_stock_count'] > 10:
                    lines.append(f"     ... è¿˜æœ‰{stock_changes['new_stock_count'] - 10}å®¶")
            
            if stock_changes['delisted_stock_count'] > 0:
                lines.append(f"\n  âŒ é€€å¸‚å…¬å¸: {stock_changes['delisted_stock_count']}å®¶")
        
        if 'financial_changes' in changes:
            financial_changes = changes['financial_changes']
            lines.append(f"\nğŸ’° è´¢åŠ¡æ•°æ®å˜åŒ–:")
            lines.append(f"  â€¢ æ–°å¢: {financial_changes['new_count']}æ¡")
            lines.append(f"  â€¢ æ›´æ–°: {financial_changes['modified_count']}æ¡")
            lines.append(f"  â€¢ ä¸å˜: {financial_changes['unchanged_count']}æ¡")
        
        lines.append("\n" + "=" * 70)
        
        return "\n".join(lines)
    
    def save_changelog(self, changes: Dict, filename: str = None):
        """
        ä¿å­˜å˜æ›´æ—¥å¿—åˆ°æ–‡ä»¶
        
        Args:
            changes: å˜æ›´ä¿¡æ¯
            filename: æ–‡ä»¶åï¼Œé»˜è®¤ä¸º changelog_{timestamp}.txt
        """
        if not filename:
            filename = f"changelog_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        try:
            content = self.generate_changelog(changes)
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            logger.info(f"å˜æ›´æ—¥å¿—å·²ä¿å­˜: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜å˜æ›´æ—¥å¿—å¤±è´¥: {e}")


class VersionManager:
    """ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, history_file: str = 'version_history.json'):
        """
        åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†å™¨
        
        Args:
            history_file: ç‰ˆæœ¬å†å²æ–‡ä»¶
        """
        self.history_file = history_file
        self.history = self.load_history()
    
    def load_history(self) -> List[Dict]:
        """åŠ è½½ç‰ˆæœ¬å†å²"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½ç‰ˆæœ¬å†å²å¤±è´¥: {e}")
        return []
    
    def save_history(self):
        """ä¿å­˜ç‰ˆæœ¬å†å²"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ç‰ˆæœ¬å†å²å¤±è´¥: {e}")
    
    def record_version(self, version: str, metadata: Dict):
        """
        è®°å½•æ–°ç‰ˆæœ¬
        
        Args:
            version: ç‰ˆæœ¬å·
            metadata: ç‰ˆæœ¬å…ƒæ•°æ®
        """
        entry = {
            'version': version,
            'timestamp': datetime.now().isoformat(),
            'total_stocks': metadata.get('total_stocks'),
            'total_records': metadata.get('total_records'),
            'data_completeness': metadata.get('data_completeness'),
            'notes': metadata.get('notes', '')
        }
        
        self.history.append(entry)
        self.save_history()
        logger.info(f"ç‰ˆæœ¬å·²è®°å½•: {version}")
    
    def get_version_history(self) -> List[Dict]:
        """è·å–å®Œæ•´çš„ç‰ˆæœ¬å†å²"""
        return self.history
    
    def get_latest_version(self) -> Optional[Dict]:
        """è·å–æœ€æ–°ç‰ˆæœ¬ä¿¡æ¯"""
        if self.history:
            return self.history[-1]
        return None
